{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WALKING_RECOGNITION_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1bQps0hDX9GVN0NmthAET4JoxjFQ2QjtS",
      "authorship_tag": "ABX9TyOUB9kxcMAK4Wuss3tR515u"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d30e5e9f-6876-448c-829a-8163e6cc5315",
        "id": "zDhdssmybcxl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        }
      },
      "source": [
        "!pip install tensorflow==1.15.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 35kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.34.2)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 45.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 45.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.10.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.28.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (46.1.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=5a8f9f43f53eead696bdfbbe860b5454c4afe70fb55ce4ac22714c0c2b7ecb86\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, gast, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "  Found existing installation: tensorboard 2.2.0\n",
            "    Uninstalling tensorboard-2.2.0:\n",
            "      Successfully uninstalled tensorboard-2.2.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.2.0rc2\n",
            "    Uninstalling tensorflow-2.2.0rc2:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc2\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jf-FbPaX76v",
        "colab_type": "code",
        "outputId": "1d8c8430-f5c5-4fbc-e87f-69608c98addf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "print(tf.__version__)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f48df3a5-26c2-4939-ea50-3aac3b7bda93",
        "id": "nIGEtxpDbcx0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/drive/My Drive/walking/wlaking.csv\")\n",
        "data.head()\n",
        "data.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(149332, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f659ce3c-0ca8-4fe4-cee3-c83e6306cdbf",
        "id": "Z7y2Kd1DbcyB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Check for Duplicates\n",
        "print('No of duplicates in DATA: {}'.format(sum(data.duplicated())))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No of duplicates in DATA: 448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3806bf3b-98e1-4158-8284-1fd90de2fed3",
        "id": "_6qatUXQbcy7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Checking for NaN/null values\n",
        "print('We have {} NaN/Null values in data'.format(data.isnull().values.sum()))\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have 0 NaN/Null values in data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(149332, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d17bbb46-ea2a-4cb1-dd53-59f3d78c6430",
        "id": "iUHdsSKWbczP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TIMESTAMP</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>Z</th>\n",
              "      <th>USER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.69464</td>\n",
              "      <td>3.17350</td>\n",
              "      <td>7.5048</td>\n",
              "      <td>user1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.030639</td>\n",
              "      <td>0.14982</td>\n",
              "      <td>3.48680</td>\n",
              "      <td>9.2755</td>\n",
              "      <td>user1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.069763</td>\n",
              "      <td>-0.29965</td>\n",
              "      <td>1.94770</td>\n",
              "      <td>9.1120</td>\n",
              "      <td>user1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.099823</td>\n",
              "      <td>-1.68890</td>\n",
              "      <td>1.41650</td>\n",
              "      <td>10.1200</td>\n",
              "      <td>user1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.129820</td>\n",
              "      <td>-2.17930</td>\n",
              "      <td>0.95342</td>\n",
              "      <td>10.9240</td>\n",
              "      <td>user1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TIMESTAMP        X        Y        Z   USER\n",
              "0   0.000000  0.69464  3.17350   7.5048  user1\n",
              "1   0.030639  0.14982  3.48680   9.2755  user1\n",
              "2   0.069763 -0.29965  1.94770   9.1120  user1\n",
              "3   0.099823 -1.68890  1.41650  10.1200  user1\n",
              "4   0.129820 -2.17930  0.95342  10.9240  user1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L21N1TdefGXq",
        "colab_type": "code",
        "outputId": "31d90cbb-38fa-45d6-9612-02245e6c75c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "data['USER'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "user17    21991\n",
              "user18    20758\n",
              "user20    16949\n",
              "user14    12027\n",
              "user22     9698\n",
              "user9      7988\n",
              "user4      6981\n",
              "user13     6699\n",
              "user11     5636\n",
              "user1      5069\n",
              "user6      4936\n",
              "user12     4799\n",
              "user2      3882\n",
              "user7      3729\n",
              "user15     3653\n",
              "user8      3457\n",
              "user10     3086\n",
              "user21     3082\n",
              "user16     1728\n",
              "user3      1144\n",
              "user5      1129\n",
              "user19      911\n",
              "Name: USER, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAiSt0mBfK4P",
        "colab_type": "code",
        "outputId": "a3865df5-3dcd-4ccf-e5a2-e74f46e03341",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "data['X'] = data['X'].astype('float')\n",
        "data['Y'] = data['Y'].astype('float')\n",
        "data['Z'] = data['Z'].astype('float')\n",
        "data.info()\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 149332 entries, 0 to 149331\n",
            "Data columns (total 5 columns):\n",
            " #   Column     Non-Null Count   Dtype  \n",
            "---  ------     --------------   -----  \n",
            " 0   TIMESTAMP  149332 non-null  float64\n",
            " 1   X          149332 non-null  float64\n",
            " 2   Y          149332 non-null  float64\n",
            " 3   Z          149332 non-null  float64\n",
            " 4   USER       149332 non-null  object \n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 5.7+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(149332, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HGL0yFefYB4",
        "colab_type": "code",
        "outputId": "49ae0cbe-da2c-440d-9daf-5a50fb3f2895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "Fs = 20\n",
        "gt= data['USER'].value_counts().index\n",
        "gt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['user17', 'user18', 'user20', 'user14', 'user22', 'user9', 'user4',\n",
              "       'user13', 'user11', 'user1', 'user6', 'user12', 'user2', 'user7',\n",
              "       'user15', 'user8', 'user10', 'user21', 'user16', 'user3', 'user5',\n",
              "       'user19'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQNlaupefgFJ",
        "colab_type": "code",
        "outputId": "3c46dbb7-a891-49ec-bdb1-72716fb4443d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label = LabelEncoder()\n",
        "data['label'] = label.fit_transform(data['USER'])\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TIMESTAMP</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>Z</th>\n",
              "      <th>USER</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.69464</td>\n",
              "      <td>3.17350</td>\n",
              "      <td>7.5048</td>\n",
              "      <td>user1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.030639</td>\n",
              "      <td>0.14982</td>\n",
              "      <td>3.48680</td>\n",
              "      <td>9.2755</td>\n",
              "      <td>user1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.069763</td>\n",
              "      <td>-0.29965</td>\n",
              "      <td>1.94770</td>\n",
              "      <td>9.1120</td>\n",
              "      <td>user1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.099823</td>\n",
              "      <td>-1.68890</td>\n",
              "      <td>1.41650</td>\n",
              "      <td>10.1200</td>\n",
              "      <td>user1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.129820</td>\n",
              "      <td>-2.17930</td>\n",
              "      <td>0.95342</td>\n",
              "      <td>10.9240</td>\n",
              "      <td>user1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TIMESTAMP        X        Y        Z   USER  label\n",
              "0   0.000000  0.69464  3.17350   7.5048  user1      0\n",
              "1   0.030639  0.14982  3.48680   9.2755  user1      0\n",
              "2   0.069763 -0.29965  1.94770   9.1120  user1      0\n",
              "3   0.099823 -1.68890  1.41650  10.1200  user1      0\n",
              "4   0.129820 -2.17930  0.95342  10.9240  user1      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4wvLnaFfnca",
        "colab_type": "code",
        "outputId": "0e960322-a6db-487d-ca4e-66b57beb76e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "label.classes_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['user1', 'user10', 'user11', 'user12', 'user13', 'user14',\n",
              "       'user15', 'user16', 'user17', 'user18', 'user19', 'user2',\n",
              "       'user20', 'user21', 'user22', 'user3', 'user4', 'user5', 'user6',\n",
              "       'user7', 'user8', 'user9'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9L5abBlfoxm",
        "colab_type": "code",
        "outputId": "da86fc4a-8cf9-44de-99af-7697b7eb575b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "X = data[['X', 'Y', 'Z']]\n",
        "y = data['label']\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "scaled_X = pd.DataFrame(data = X, columns = ['X', 'Y', 'Z'])\n",
        "scaled_X['label'] = y.values\n",
        "\n",
        "scaled_X"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>Z</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.819672</td>\n",
              "      <td>-2.018554</td>\n",
              "      <td>2.207776</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.629638</td>\n",
              "      <td>-1.905540</td>\n",
              "      <td>2.770330</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.472862</td>\n",
              "      <td>-2.460726</td>\n",
              "      <td>2.718386</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.011710</td>\n",
              "      <td>-2.652341</td>\n",
              "      <td>3.038629</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.182762</td>\n",
              "      <td>-2.819384</td>\n",
              "      <td>3.294061</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149327</th>\n",
              "      <td>0.178317</td>\n",
              "      <td>-0.967124</td>\n",
              "      <td>2.194814</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149328</th>\n",
              "      <td>0.377849</td>\n",
              "      <td>-1.202964</td>\n",
              "      <td>2.623203</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149329</th>\n",
              "      <td>0.311336</td>\n",
              "      <td>-1.035914</td>\n",
              "      <td>2.415490</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149330</th>\n",
              "      <td>0.202070</td>\n",
              "      <td>-1.104703</td>\n",
              "      <td>2.099599</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149331</th>\n",
              "      <td>0.202070</td>\n",
              "      <td>-1.089950</td>\n",
              "      <td>2.328948</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>149332 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               X         Y         Z  label\n",
              "0       0.819672 -2.018554  2.207776      0\n",
              "1       0.629638 -1.905540  2.770330      0\n",
              "2       0.472862 -2.460726  2.718386      0\n",
              "3      -0.011710 -2.652341  3.038629      0\n",
              "4      -0.182762 -2.819384  3.294061      0\n",
              "...          ...       ...       ...    ...\n",
              "149327  0.178317 -0.967124  2.194814     14\n",
              "149328  0.377849 -1.202964  2.623203     14\n",
              "149329  0.311336 -1.035914  2.415490     14\n",
              "149330  0.202070 -1.104703  2.099599     14\n",
              "149331  0.202070 -1.089950  2.328948     14\n",
              "\n",
              "[149332 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jtmiy59Rbc00",
        "colab": {}
      },
      "source": [
        "Fs = 50\n",
        "frame_size = Fs*4 # 80\n",
        "hop_size = Fs*2 # 40\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8EkQlxyXbc05",
        "colab": {}
      },
      "source": [
        "import math as m\n",
        "def get_frames(data, frame_size):\n",
        "\n",
        "  N_FEATURES = 3\n",
        "  frames = []\n",
        "  labels = []\n",
        "  for i in range(0, len(scaled_X)- frame_size):\n",
        "    x = data['X'].values[i: i + frame_size]\n",
        "    y = data['Y'].values[i: i + frame_size]\n",
        "    z = data['Z'].values[i: i + frame_size]\n",
        "        # Retrieve the most often used label in this segment\n",
        "    label = stats.mode(scaled_X['label'][i: i + frame_size])[0][0]\n",
        "    frames.append([x, y, z])\n",
        "    labels.append(label)\n",
        "  # Bring the segments into a better shape\n",
        "  frames = np.asarray(frames, dtype= np.float32).reshape(-1, frame_size, N_FEATURES)\n",
        "  labels = np.asarray(labels)\n",
        "  return frames, labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCpEJ23LgFXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X,y = get_frames(scaled_X, frame_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpVCSxrqhRm4",
        "colab_type": "code",
        "outputId": "d6f52e33-be81-4975-fabc-72148c7ef0fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape\n",
        "#y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(149132, 200, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bRc8aHwha4i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 0, stratify = y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IGULdIKhdpu",
        "colab_type": "code",
        "outputId": "362188da-b225-48b0-f239-3b6788b69f26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((119305, 200, 3), (29827, 200, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z45rOPQMRLK",
        "colab_type": "code",
        "outputId": "354a1894-b911-4d52-bb3c-ceb3c7f27aeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train = X_train.reshape(119305, 200, 3,1)\n",
        "X_test = X_test.reshape(29827, 200, 3,1)\n",
        "X_train[0].shape, X_test[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((200, 3, 1), (200, 3, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx5ufXF5NWB-",
        "colab_type": "code",
        "outputId": "69151b4f-5f8e-44ef-a2dd-f6ea9439c998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Importing libraries\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.core import Dense, Dropout"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzkYLzMfdwXL",
        "colab_type": "code",
        "outputId": "a689e266-4f30-4839-cde1-1ec111cbe07e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=16, kernel_size=(3,3), padding='same', activation='relu',input_shape=X_train[0].shape))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(22, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 200, 3, 16)        160       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 200, 3, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 100, 1, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              1639424   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 22)                22550     \n",
            "=================================================================\n",
            "Total params: 1,662,134\n",
            "Trainable params: 1,662,134\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSRSMKjIecw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "sgd = optimizers.adam(lr=0.0001)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX_iqGtZegEs",
        "colab_type": "code",
        "outputId": "58cbebc0-f24e-4699-eeed-2ed3d81115fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "history = model.fit(X_train, y_train, epochs =30, validation_data= (X_test, y_test),batch_size=64, verbose=1)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "print(\"complete !!!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 119305 samples, validate on 29827 samples\n",
            "Epoch 1/30\n",
            "119305/119305 [==============================] - 16s 133us/step - loss: 1.0989 - accuracy: 0.6574 - val_loss: 0.5854 - val_accuracy: 0.8514\n",
            "Epoch 2/30\n",
            "119305/119305 [==============================] - 9s 78us/step - loss: 0.4636 - accuracy: 0.8520 - val_loss: 0.3333 - val_accuracy: 0.9222\n",
            "Epoch 3/30\n",
            "119305/119305 [==============================] - 9s 76us/step - loss: 0.2949 - accuracy: 0.9065 - val_loss: 0.2264 - val_accuracy: 0.9537\n",
            "Epoch 4/30\n",
            "119305/119305 [==============================] - 9s 77us/step - loss: 0.2081 - accuracy: 0.9345 - val_loss: 0.1613 - val_accuracy: 0.9691\n",
            "Epoch 5/30\n",
            "119305/119305 [==============================] - 9s 78us/step - loss: 0.1536 - accuracy: 0.9524 - val_loss: 0.1217 - val_accuracy: 0.9789\n",
            "Epoch 6/30\n",
            "119305/119305 [==============================] - 9s 77us/step - loss: 0.1192 - accuracy: 0.9632 - val_loss: 0.0906 - val_accuracy: 0.9844\n",
            "Epoch 7/30\n",
            "119305/119305 [==============================] - 9s 77us/step - loss: 0.0963 - accuracy: 0.9705 - val_loss: 0.0704 - val_accuracy: 0.9886\n",
            "Epoch 8/30\n",
            "119305/119305 [==============================] - 10s 80us/step - loss: 0.0796 - accuracy: 0.9757 - val_loss: 0.0604 - val_accuracy: 0.9901\n",
            "Epoch 9/30\n",
            "119305/119305 [==============================] - 9s 77us/step - loss: 0.0663 - accuracy: 0.9803 - val_loss: 0.0486 - val_accuracy: 0.9931\n",
            "Epoch 10/30\n",
            "119305/119305 [==============================] - 9s 77us/step - loss: 0.0570 - accuracy: 0.9824 - val_loss: 0.0399 - val_accuracy: 0.9946\n",
            "Epoch 11/30\n",
            "119305/119305 [==============================] - 9s 77us/step - loss: 0.0504 - accuracy: 0.9846 - val_loss: 0.0367 - val_accuracy: 0.9943\n",
            "Epoch 12/30\n",
            "119305/119305 [==============================] - 9s 78us/step - loss: 0.0442 - accuracy: 0.9862 - val_loss: 0.0279 - val_accuracy: 0.9971\n",
            "Epoch 13/30\n",
            "119305/119305 [==============================] - 9s 76us/step - loss: 0.0392 - accuracy: 0.9882 - val_loss: 0.0278 - val_accuracy: 0.9964\n",
            "Epoch 14/30\n",
            "119305/119305 [==============================] - 9s 77us/step - loss: 0.0346 - accuracy: 0.9896 - val_loss: 0.0223 - val_accuracy: 0.9971\n",
            "Epoch 15/30\n",
            "119305/119305 [==============================] - 9s 77us/step - loss: 0.0318 - accuracy: 0.9905 - val_loss: 0.0186 - val_accuracy: 0.9975\n",
            "Epoch 16/30\n",
            "119305/119305 [==============================] - 9s 75us/step - loss: 0.0292 - accuracy: 0.9915 - val_loss: 0.0193 - val_accuracy: 0.9971\n",
            "Epoch 17/30\n",
            "119305/119305 [==============================] - 9s 77us/step - loss: 0.0268 - accuracy: 0.9919 - val_loss: 0.0175 - val_accuracy: 0.9980\n",
            "Epoch 18/30\n",
            "119305/119305 [==============================] - 9s 77us/step - loss: 0.0250 - accuracy: 0.9923 - val_loss: 0.0140 - val_accuracy: 0.9989\n",
            "Epoch 19/30\n",
            "119305/119305 [==============================] - 9s 77us/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 0.0202 - val_accuracy: 0.9956\n",
            "Epoch 20/30\n",
            "119305/119305 [==============================] - 9s 77us/step - loss: 0.0214 - accuracy: 0.9934 - val_loss: 0.0135 - val_accuracy: 0.9984\n",
            "Epoch 21/30\n",
            "119305/119305 [==============================] - 9s 78us/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.0103 - val_accuracy: 0.9994\n",
            "Epoch 22/30\n",
            "119305/119305 [==============================] - 9s 77us/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 0.0098 - val_accuracy: 0.9991\n",
            "Epoch 23/30\n",
            "119305/119305 [==============================] - 9s 76us/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.0105 - val_accuracy: 0.9991\n",
            "Epoch 24/30\n",
            "119305/119305 [==============================] - 9s 77us/step - loss: 0.0168 - accuracy: 0.9950 - val_loss: 0.0079 - val_accuracy: 0.9995\n",
            "Epoch 25/30\n",
            "119305/119305 [==============================] - 9s 77us/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.0086 - val_accuracy: 0.9992\n",
            "Epoch 26/30\n",
            "119305/119305 [==============================] - 9s 76us/step - loss: 0.0153 - accuracy: 0.9955 - val_loss: 0.0105 - val_accuracy: 0.9983\n",
            "Epoch 27/30\n",
            "119305/119305 [==============================] - 9s 75us/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 0.0076 - val_accuracy: 0.9994\n",
            "Epoch 28/30\n",
            "119305/119305 [==============================] - 9s 76us/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 0.0103 - val_accuracy: 0.9982\n",
            "Epoch 29/30\n",
            "119305/119305 [==============================] - 9s 77us/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 0.0064 - val_accuracy: 0.9994\n",
            "Epoch 30/30\n",
            "119305/119305 [==============================] - 9s 76us/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.0071 - val_accuracy: 0.9989\n",
            "--- 283.9927785396576 seconds ---\n",
            "complete !!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQya7dGhoOlv",
        "colab_type": "code",
        "outputId": "87f88589-f73e-4b1f-c14a-0df9e212af23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict_classes(X_test)\n",
        "mat = confusion_matrix(y_test, y_pred)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "plot_confusion_matrix(conf_mat=mat, show_normed=True,cmap=plt.cm.Blues,show_absolute=True, figsize=(15,15),colorbar=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 994    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0  616    1    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0 1127    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    1  959    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0 1340    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    1 2405    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0  731    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0  344    2    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4398    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    5    0    0    0    0    0   12 4135    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0  182    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0  776    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0 3390    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0  616\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  1920    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0  228    1    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0 1394    2    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0  226    0    0    0    0]\n",
            " [   0    0    0    2    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0  985    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0  744    2    0]\n",
            " [   0    0    0    0    0    0    0    0    0    3    0    0    0    0\n",
            "     0    0    0    0    0    0  688    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    1 1596]]\n",
            "0.9988936198746102\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       994\n",
            "           1       1.00      1.00      1.00       617\n",
            "           2       0.99      1.00      1.00      1127\n",
            "           3       1.00      1.00      1.00       960\n",
            "           4       1.00      1.00      1.00      1340\n",
            "           5       1.00      1.00      1.00      2406\n",
            "           6       1.00      1.00      1.00       731\n",
            "           7       1.00      0.99      1.00       346\n",
            "           8       1.00      1.00      1.00      4398\n",
            "           9       1.00      1.00      1.00      4152\n",
            "          10       1.00      1.00      1.00       182\n",
            "          11       1.00      1.00      1.00       776\n",
            "          12       1.00      1.00      1.00      3390\n",
            "          13       1.00      1.00      1.00       616\n",
            "          14       1.00      1.00      1.00      1920\n",
            "          15       1.00      1.00      1.00       229\n",
            "          16       1.00      1.00      1.00      1396\n",
            "          17       0.99      1.00      1.00       226\n",
            "          18       1.00      1.00      1.00       987\n",
            "          19       1.00      1.00      1.00       746\n",
            "          20       1.00      1.00      1.00       691\n",
            "          21       1.00      1.00      1.00      1597\n",
            "\n",
            "    accuracy                           1.00     29827\n",
            "   macro avg       1.00      1.00      1.00     29827\n",
            "weighted avg       1.00      1.00      1.00     29827\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Figure size 1080x1080 with 2 Axes>,\n",
              " <matplotlib.axes._subplots.AxesSubplot at 0x7f9de01aca20>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av3b7ZuloL82",
        "colab_type": "code",
        "outputId": "3f555ae6-07aa-419b-d6f7-bfc35508c53b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977
        }
      },
      "source": [
        "import matplotlib.pyplot as plt1\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(history.history['accuracy'],label='Train acc')\n",
        "plt.plot(history.history['val_accuracy'],label = 'Validation acc')\n",
        "plt.xlabel('epoch no')\n",
        "plt.ylabel('acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(history.history['loss'],label='Train loss')\n",
        "plt.plot(history.history['val_loss'],label = 'Validation loss')\n",
        "plt.xlabel('epoch no')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymQWwtZmswt0",
        "colab_type": "code",
        "outputId": "2dac7a09-5eef-47bd-c32e-89f89c5f4a62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "history.history['accuracy']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.65740746,\n",
              " 0.8520431,\n",
              " 0.906475,\n",
              " 0.9344872,\n",
              " 0.9523574,\n",
              " 0.9631868,\n",
              " 0.9705209,\n",
              " 0.9757009,\n",
              " 0.9802774,\n",
              " 0.98240644,\n",
              " 0.98462766,\n",
              " 0.9862202,\n",
              " 0.9881732,\n",
              " 0.9895981,\n",
              " 0.99045306,\n",
              " 0.99146724,\n",
              " 0.9918612,\n",
              " 0.9922803,\n",
              " 0.99328613,\n",
              " 0.9933867,\n",
              " 0.99368846,\n",
              " 0.9939064,\n",
              " 0.9947278,\n",
              " 0.9949876,\n",
              " 0.99485356,\n",
              " 0.995457,\n",
              " 0.9955157,\n",
              " 0.9959767,\n",
              " 0.9960354,\n",
              " 0.99575037]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0St-BcJVupDX",
        "colab_type": "code",
        "outputId": "fb0a3cd4-2bab-40cf-ad11-d46304263c77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "history.history['val_accuracy']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8514097929000854,\n",
              " 0.9221845865249634,\n",
              " 0.9537332057952881,\n",
              " 0.9690548777580261,\n",
              " 0.978945255279541,\n",
              " 0.9843765497207642,\n",
              " 0.9886009097099304,\n",
              " 0.9901431798934937,\n",
              " 0.9930934906005859,\n",
              " 0.9946022033691406,\n",
              " 0.9943004846572876,\n",
              " 0.9970831871032715,\n",
              " 0.9964126348495483,\n",
              " 0.9970831871032715,\n",
              " 0.9974855184555054,\n",
              " 0.9971166849136353,\n",
              " 0.9979884028434753,\n",
              " 0.9988601207733154,\n",
              " 0.9956080317497253,\n",
              " 0.9983907341957092,\n",
              " 0.9993630051612854,\n",
              " 0.9990612268447876,\n",
              " 0.9990947842597961,\n",
              " 0.9994635581970215,\n",
              " 0.9991953372955322,\n",
              " 0.9982901215553284,\n",
              " 0.9993630051612854,\n",
              " 0.9981560111045837,\n",
              " 0.9993965029716492,\n",
              " 0.9988936185836792]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG1zii5BtBg3",
        "colab_type": "code",
        "outputId": "b9632290-21c0-4afc-fceb-2e7313abb023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "history.history['loss']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0989370930445155,\n",
              " 0.4636032994667486,\n",
              " 0.29485684562917724,\n",
              " 0.20810918893764527,\n",
              " 0.1536274496307767,\n",
              " 0.11917600458901052,\n",
              " 0.09632846452999902,\n",
              " 0.0795648324995937,\n",
              " 0.06626476464895895,\n",
              " 0.05699144357583618,\n",
              " 0.0503819875245217,\n",
              " 0.04416113010543785,\n",
              " 0.03915182162508856,\n",
              " 0.034607218496171356,\n",
              " 0.03182351004478593,\n",
              " 0.029226313081048436,\n",
              " 0.02682961067176902,\n",
              " 0.024966603484590046,\n",
              " 0.022328173435762804,\n",
              " 0.021435899825499007,\n",
              " 0.020119914507959063,\n",
              " 0.02004323299639667,\n",
              " 0.017801878053602775,\n",
              " 0.016846262091579915,\n",
              " 0.016698944109912486,\n",
              " 0.015347872272604231,\n",
              " 0.014892407019810091,\n",
              " 0.013775953760017823,\n",
              " 0.01337428597829756,\n",
              " 0.014096265412980416]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUbpxY24usTx",
        "colab_type": "code",
        "outputId": "9ae2632f-93cc-4818-f9d6-42bd81d0a716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "history.history['val_loss']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5854361059989251,\n",
              " 0.3333272102753236,\n",
              " 0.22640475057359993,\n",
              " 0.16132072794588084,\n",
              " 0.12172709411142474,\n",
              " 0.09058255269165774,\n",
              " 0.07040726183834807,\n",
              " 0.06036926194929024,\n",
              " 0.0486377292807678,\n",
              " 0.03989695949259433,\n",
              " 0.03671444766760486,\n",
              " 0.027918866777551336,\n",
              " 0.027783758102816858,\n",
              " 0.02234584704996565,\n",
              " 0.018597840925565393,\n",
              " 0.01925626141591348,\n",
              " 0.01747527820014672,\n",
              " 0.014002711648254429,\n",
              " 0.020205349304361755,\n",
              " 0.013456451096718267,\n",
              " 0.010272843012260318,\n",
              " 0.009837532228609967,\n",
              " 0.010486350272293082,\n",
              " 0.007904511578338597,\n",
              " 0.008620167009944736,\n",
              " 0.01054714060543908,\n",
              " 0.007572921398259869,\n",
              " 0.010251856580668009,\n",
              " 0.006430847163650498,\n",
              " 0.00706173690536634]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ56AUREf18W",
        "colab_type": "code",
        "outputId": "4d9779b8-7bb7-4304-dd2b-78b12fed8083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras import optimizers\n",
        "\n",
        "fruits = [64,128,256,512,1024]\n",
        "for x in fruits:\n",
        "  print(x)\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(filters=16, kernel_size=(3,3), padding='same', activation='relu',input_shape=X_train[0].shape))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(MaxPooling2D(pool_size=2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(22, activation='softmax'))\n",
        "  model.summary()\n",
        "  sgd = optimizers.adam(lr=0.0001)\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "  history = model.fit(X_train, y_train, epochs =30, validation_data= (X_test, y_test),batch_size=x, verbose=1)  \n",
        "  y_pred = model.predict_classes(X_test)\n",
        "  mat = confusion_matrix(y_test, y_pred)\n",
        "  print(confusion_matrix(y_test, y_pred))\n",
        "  print(accuracy_score(y_test,y_pred))\n",
        "  print(classification_report(y_test,y_pred))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 200, 3, 16)        160       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 200, 3, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 100, 1, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              1639424   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 22)                22550     \n",
            "=================================================================\n",
            "Total params: 1,662,134\n",
            "Trainable params: 1,662,134\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 119305 samples, validate on 29827 samples\n",
            "Epoch 1/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 1.0929 - accuracy: 0.6530 - val_loss: 0.6074 - val_accuracy: 0.8399\n",
            "Epoch 2/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.4840 - accuracy: 0.8435 - val_loss: 0.3546 - val_accuracy: 0.9115\n",
            "Epoch 3/30\n",
            "119305/119305 [==============================] - 9s 78us/step - loss: 0.3068 - accuracy: 0.9016 - val_loss: 0.2290 - val_accuracy: 0.9546\n",
            "Epoch 4/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.2156 - accuracy: 0.9322 - val_loss: 0.1667 - val_accuracy: 0.9638\n",
            "Epoch 5/30\n",
            "119305/119305 [==============================] - 9s 80us/step - loss: 0.1625 - accuracy: 0.9491 - val_loss: 0.1293 - val_accuracy: 0.9762\n",
            "Epoch 6/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.1273 - accuracy: 0.9603 - val_loss: 0.0980 - val_accuracy: 0.9820\n",
            "Epoch 7/30\n",
            "119305/119305 [==============================] - 9s 78us/step - loss: 0.1046 - accuracy: 0.9672 - val_loss: 0.0774 - val_accuracy: 0.9891\n",
            "Epoch 8/30\n",
            "119305/119305 [==============================] - 9s 78us/step - loss: 0.0858 - accuracy: 0.9728 - val_loss: 0.0606 - val_accuracy: 0.9912\n",
            "Epoch 9/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.0728 - accuracy: 0.9772 - val_loss: 0.0578 - val_accuracy: 0.9874\n",
            "Epoch 10/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.0620 - accuracy: 0.9808 - val_loss: 0.0435 - val_accuracy: 0.9950\n",
            "Epoch 11/30\n",
            "119305/119305 [==============================] - 9s 78us/step - loss: 0.0551 - accuracy: 0.9829 - val_loss: 0.0348 - val_accuracy: 0.9959\n",
            "Epoch 12/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.0492 - accuracy: 0.9850 - val_loss: 0.0317 - val_accuracy: 0.9952\n",
            "Epoch 13/30\n",
            "119305/119305 [==============================] - 9s 78us/step - loss: 0.0437 - accuracy: 0.9864 - val_loss: 0.0299 - val_accuracy: 0.9954\n",
            "Epoch 14/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.0396 - accuracy: 0.9877 - val_loss: 0.0250 - val_accuracy: 0.9974\n",
            "Epoch 15/30\n",
            "119305/119305 [==============================] - 9s 78us/step - loss: 0.0356 - accuracy: 0.9889 - val_loss: 0.0248 - val_accuracy: 0.9965\n",
            "Epoch 16/30\n",
            "119305/119305 [==============================] - 9s 78us/step - loss: 0.0341 - accuracy: 0.9896 - val_loss: 0.0221 - val_accuracy: 0.9973\n",
            "Epoch 17/30\n",
            "119305/119305 [==============================] - 9s 78us/step - loss: 0.0295 - accuracy: 0.9910 - val_loss: 0.0214 - val_accuracy: 0.9973\n",
            "Epoch 18/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.0276 - accuracy: 0.9919 - val_loss: 0.0181 - val_accuracy: 0.9975\n",
            "Epoch 19/30\n",
            "119305/119305 [==============================] - 10s 80us/step - loss: 0.0263 - accuracy: 0.9919 - val_loss: 0.0139 - val_accuracy: 0.9991\n",
            "Epoch 20/30\n",
            "119305/119305 [==============================] - 9s 78us/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 0.0147 - val_accuracy: 0.9986\n",
            "Epoch 21/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.0220 - accuracy: 0.9932 - val_loss: 0.0130 - val_accuracy: 0.9990\n",
            "Epoch 22/30\n",
            "119305/119305 [==============================] - 9s 78us/step - loss: 0.0219 - accuracy: 0.9930 - val_loss: 0.0103 - val_accuracy: 0.9990\n",
            "Epoch 23/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.0202 - accuracy: 0.9938 - val_loss: 0.0114 - val_accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "119305/119305 [==============================] - 9s 78us/step - loss: 0.0192 - accuracy: 0.9941 - val_loss: 0.0100 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.0088 - val_accuracy: 0.9993\n",
            "Epoch 26/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.0088 - val_accuracy: 0.9993\n",
            "Epoch 27/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.0078 - val_accuracy: 0.9993\n",
            "Epoch 28/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.0155 - accuracy: 0.9952 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
            "Epoch 29/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.0089 - val_accuracy: 0.9985\n",
            "Epoch 30/30\n",
            "119305/119305 [==============================] - 9s 78us/step - loss: 0.0147 - accuracy: 0.9955 - val_loss: 0.0071 - val_accuracy: 0.9993\n",
            "[[ 994    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0  616    1    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0 1127    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    1  959    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0 1340    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0 2406    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0  730    0    1    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0  343    3    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    1 4397    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4152    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    1  181    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0  776    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0 3390    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0  616\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  1920    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0  228    1    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0 1394    2    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0  226    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0  987    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    3    0    0    0    0\n",
            "     0    0    0    0    0  742    1    0]\n",
            " [   0    0    0    0    0    0    0    0    0    5    0    0    0    0\n",
            "     0    0    0    0    0    0  686    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    1 1596]]\n",
            "0.9992959399202065\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       994\n",
            "           1       1.00      1.00      1.00       617\n",
            "           2       1.00      1.00      1.00      1127\n",
            "           3       1.00      1.00      1.00       960\n",
            "           4       1.00      1.00      1.00      1340\n",
            "           5       1.00      1.00      1.00      2406\n",
            "           6       1.00      1.00      1.00       731\n",
            "           7       1.00      0.99      0.99       346\n",
            "           8       1.00      1.00      1.00      4398\n",
            "           9       1.00      1.00      1.00      4152\n",
            "          10       1.00      0.99      1.00       182\n",
            "          11       1.00      1.00      1.00       776\n",
            "          12       1.00      1.00      1.00      3390\n",
            "          13       1.00      1.00      1.00       616\n",
            "          14       1.00      1.00      1.00      1920\n",
            "          15       1.00      1.00      1.00       229\n",
            "          16       1.00      1.00      1.00      1396\n",
            "          17       0.99      1.00      1.00       226\n",
            "          18       1.00      1.00      1.00       987\n",
            "          19       1.00      0.99      1.00       746\n",
            "          20       1.00      0.99      0.99       691\n",
            "          21       1.00      1.00      1.00      1597\n",
            "\n",
            "    accuracy                           1.00     29827\n",
            "   macro avg       1.00      1.00      1.00     29827\n",
            "weighted avg       1.00      1.00      1.00     29827\n",
            "\n",
            "128\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 200, 3, 16)        160       \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 200, 3, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 100, 1, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1024)              1639424   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 22)                22550     \n",
            "=================================================================\n",
            "Total params: 1,662,134\n",
            "Trainable params: 1,662,134\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 119305 samples, validate on 29827 samples\n",
            "Epoch 1/30\n",
            "119305/119305 [==============================] - 6s 49us/step - loss: 1.2646 - accuracy: 0.6086 - val_loss: 0.7517 - val_accuracy: 0.8038\n",
            "Epoch 2/30\n",
            "119305/119305 [==============================] - 5s 46us/step - loss: 0.5972 - accuracy: 0.8106 - val_loss: 0.4548 - val_accuracy: 0.8879\n",
            "Epoch 3/30\n",
            "119305/119305 [==============================] - 5s 46us/step - loss: 0.3916 - accuracy: 0.8768 - val_loss: 0.3084 - val_accuracy: 0.9285\n",
            "Epoch 4/30\n",
            "119305/119305 [==============================] - 5s 45us/step - loss: 0.2832 - accuracy: 0.9115 - val_loss: 0.2305 - val_accuracy: 0.9520\n",
            "Epoch 5/30\n",
            "119305/119305 [==============================] - 5s 46us/step - loss: 0.2140 - accuracy: 0.9345 - val_loss: 0.1695 - val_accuracy: 0.9731\n",
            "Epoch 6/30\n",
            "119305/119305 [==============================] - 5s 46us/step - loss: 0.1687 - accuracy: 0.9498 - val_loss: 0.1379 - val_accuracy: 0.9766\n",
            "Epoch 7/30\n",
            "119305/119305 [==============================] - 6s 46us/step - loss: 0.1352 - accuracy: 0.9598 - val_loss: 0.1078 - val_accuracy: 0.9829\n",
            "Epoch 8/30\n",
            "119305/119305 [==============================] - 5s 46us/step - loss: 0.1125 - accuracy: 0.9666 - val_loss: 0.0893 - val_accuracy: 0.9849\n",
            "Epoch 9/30\n",
            "119305/119305 [==============================] - 5s 45us/step - loss: 0.0924 - accuracy: 0.9726 - val_loss: 0.0746 - val_accuracy: 0.9884\n",
            "Epoch 10/30\n",
            "119305/119305 [==============================] - 5s 46us/step - loss: 0.0791 - accuracy: 0.9769 - val_loss: 0.0634 - val_accuracy: 0.9911\n",
            "Epoch 11/30\n",
            "119305/119305 [==============================] - 6s 46us/step - loss: 0.0683 - accuracy: 0.9799 - val_loss: 0.0535 - val_accuracy: 0.9922\n",
            "Epoch 12/30\n",
            "119305/119305 [==============================] - 6s 46us/step - loss: 0.0590 - accuracy: 0.9831 - val_loss: 0.0454 - val_accuracy: 0.9936\n",
            "Epoch 13/30\n",
            "119305/119305 [==============================] - 5s 45us/step - loss: 0.0520 - accuracy: 0.9849 - val_loss: 0.0405 - val_accuracy: 0.9952\n",
            "Epoch 14/30\n",
            "119305/119305 [==============================] - 5s 46us/step - loss: 0.0470 - accuracy: 0.9860 - val_loss: 0.0342 - val_accuracy: 0.9958\n",
            "Epoch 15/30\n",
            "119305/119305 [==============================] - 5s 45us/step - loss: 0.0418 - accuracy: 0.9882 - val_loss: 0.0304 - val_accuracy: 0.9952\n",
            "Epoch 16/30\n",
            "119305/119305 [==============================] - 5s 46us/step - loss: 0.0383 - accuracy: 0.9892 - val_loss: 0.0253 - val_accuracy: 0.9976\n",
            "Epoch 17/30\n",
            "119305/119305 [==============================] - 5s 46us/step - loss: 0.0340 - accuracy: 0.9902 - val_loss: 0.0228 - val_accuracy: 0.9975\n",
            "Epoch 18/30\n",
            "119305/119305 [==============================] - 5s 45us/step - loss: 0.0322 - accuracy: 0.9905 - val_loss: 0.0222 - val_accuracy: 0.9980\n",
            "Epoch 19/30\n",
            "119305/119305 [==============================] - 5s 46us/step - loss: 0.0287 - accuracy: 0.9917 - val_loss: 0.0195 - val_accuracy: 0.9979\n",
            "Epoch 20/30\n",
            "119305/119305 [==============================] - 5s 46us/step - loss: 0.0259 - accuracy: 0.9927 - val_loss: 0.0171 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "119305/119305 [==============================] - 5s 46us/step - loss: 0.0249 - accuracy: 0.9929 - val_loss: 0.0161 - val_accuracy: 0.9986\n",
            "Epoch 22/30\n",
            "119305/119305 [==============================] - 5s 46us/step - loss: 0.0229 - accuracy: 0.9934 - val_loss: 0.0184 - val_accuracy: 0.9975\n",
            "Epoch 23/30\n",
            "119305/119305 [==============================] - 5s 46us/step - loss: 0.0221 - accuracy: 0.9938 - val_loss: 0.0146 - val_accuracy: 0.9988\n",
            "Epoch 24/30\n",
            "119305/119305 [==============================] - 5s 46us/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 0.0128 - val_accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "119305/119305 [==============================] - 6s 46us/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 0.0148 - val_accuracy: 0.9976\n",
            "Epoch 26/30\n",
            "119305/119305 [==============================] - 5s 46us/step - loss: 0.0182 - accuracy: 0.9949 - val_loss: 0.0128 - val_accuracy: 0.9983\n",
            "Epoch 27/30\n",
            "119305/119305 [==============================] - 5s 46us/step - loss: 0.0173 - accuracy: 0.9950 - val_loss: 0.0099 - val_accuracy: 0.9995\n",
            "Epoch 28/30\n",
            "119305/119305 [==============================] - 5s 46us/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.0081 - val_accuracy: 0.9993\n",
            "Epoch 29/30\n",
            "119305/119305 [==============================] - 5s 46us/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.0082 - val_accuracy: 0.9991\n",
            "Epoch 30/30\n",
            "119305/119305 [==============================] - 5s 46us/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.0082 - val_accuracy: 0.9993\n",
            "[[ 994    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0  616    1    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0 1127    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    1  959    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0 1340    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0 2406    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0  731    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0  344    2    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    1 4397    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4152    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0  182    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0  776    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    1    0    0    0 3389    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0  616\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  1920    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0  228    1    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    1    0    0    0    0\n",
            "     0    0 1393    2    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0  226    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0  987    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0  746    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0   10    0    0    0    0\n",
            "     0    0    0    0    0    0  681    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    1 1596]]\n",
            "0.9992959399202065\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       994\n",
            "           1       1.00      1.00      1.00       617\n",
            "           2       1.00      1.00      1.00      1127\n",
            "           3       1.00      1.00      1.00       960\n",
            "           4       1.00      1.00      1.00      1340\n",
            "           5       1.00      1.00      1.00      2406\n",
            "           6       1.00      1.00      1.00       731\n",
            "           7       1.00      0.99      1.00       346\n",
            "           8       1.00      1.00      1.00      4398\n",
            "           9       1.00      1.00      1.00      4152\n",
            "          10       1.00      1.00      1.00       182\n",
            "          11       1.00      1.00      1.00       776\n",
            "          12       1.00      1.00      1.00      3390\n",
            "          13       1.00      1.00      1.00       616\n",
            "          14       1.00      1.00      1.00      1920\n",
            "          15       1.00      1.00      1.00       229\n",
            "          16       1.00      1.00      1.00      1396\n",
            "          17       0.99      1.00      1.00       226\n",
            "          18       1.00      1.00      1.00       987\n",
            "          19       1.00      1.00      1.00       746\n",
            "          20       1.00      0.99      0.99       691\n",
            "          21       1.00      1.00      1.00      1597\n",
            "\n",
            "    accuracy                           1.00     29827\n",
            "   macro avg       1.00      1.00      1.00     29827\n",
            "weighted avg       1.00      1.00      1.00     29827\n",
            "\n",
            "256\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 200, 3, 16)        160       \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 200, 3, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 100, 1, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1024)              1639424   \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 22)                22550     \n",
            "=================================================================\n",
            "Total params: 1,662,134\n",
            "Trainable params: 1,662,134\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 119305 samples, validate on 29827 samples\n",
            "Epoch 1/30\n",
            "119305/119305 [==============================] - 4s 34us/step - loss: 1.4477 - accuracy: 0.5524 - val_loss: 0.9691 - val_accuracy: 0.7353\n",
            "Epoch 2/30\n",
            "119305/119305 [==============================] - 3s 28us/step - loss: 0.7989 - accuracy: 0.7401 - val_loss: 0.6458 - val_accuracy: 0.8302\n",
            "Epoch 3/30\n",
            "119305/119305 [==============================] - 3s 29us/step - loss: 0.5722 - accuracy: 0.8145 - val_loss: 0.4729 - val_accuracy: 0.8905\n",
            "Epoch 4/30\n",
            "119305/119305 [==============================] - 3s 28us/step - loss: 0.4350 - accuracy: 0.8614 - val_loss: 0.3705 - val_accuracy: 0.9145\n",
            "Epoch 5/30\n",
            "119305/119305 [==============================] - 3s 29us/step - loss: 0.3432 - accuracy: 0.8921 - val_loss: 0.2896 - val_accuracy: 0.9447\n",
            "Epoch 6/30\n",
            "119305/119305 [==============================] - 3s 29us/step - loss: 0.2778 - accuracy: 0.9140 - val_loss: 0.2346 - val_accuracy: 0.9562\n",
            "Epoch 7/30\n",
            "119305/119305 [==============================] - 3s 29us/step - loss: 0.2300 - accuracy: 0.9289 - val_loss: 0.1917 - val_accuracy: 0.9684\n",
            "Epoch 8/30\n",
            "119305/119305 [==============================] - 3s 29us/step - loss: 0.1916 - accuracy: 0.9419 - val_loss: 0.1597 - val_accuracy: 0.9736\n",
            "Epoch 9/30\n",
            "119305/119305 [==============================] - 3s 29us/step - loss: 0.1630 - accuracy: 0.9519 - val_loss: 0.1389 - val_accuracy: 0.9793\n",
            "Epoch 10/30\n",
            "119305/119305 [==============================] - 3s 28us/step - loss: 0.1397 - accuracy: 0.9589 - val_loss: 0.1166 - val_accuracy: 0.9840\n",
            "Epoch 11/30\n",
            "119305/119305 [==============================] - 3s 28us/step - loss: 0.1219 - accuracy: 0.9640 - val_loss: 0.1013 - val_accuracy: 0.9859\n",
            "Epoch 12/30\n",
            "119305/119305 [==============================] - 3s 28us/step - loss: 0.1073 - accuracy: 0.9687 - val_loss: 0.0879 - val_accuracy: 0.9899\n",
            "Epoch 13/30\n",
            "119305/119305 [==============================] - 3s 28us/step - loss: 0.0951 - accuracy: 0.9721 - val_loss: 0.0765 - val_accuracy: 0.9905\n",
            "Epoch 14/30\n",
            "119305/119305 [==============================] - 3s 29us/step - loss: 0.0848 - accuracy: 0.9758 - val_loss: 0.0686 - val_accuracy: 0.9902\n",
            "Epoch 15/30\n",
            "119305/119305 [==============================] - 3s 29us/step - loss: 0.0751 - accuracy: 0.9785 - val_loss: 0.0589 - val_accuracy: 0.9920\n",
            "Epoch 16/30\n",
            "119305/119305 [==============================] - 3s 29us/step - loss: 0.0693 - accuracy: 0.9802 - val_loss: 0.0518 - val_accuracy: 0.9941\n",
            "Epoch 17/30\n",
            "119305/119305 [==============================] - 3s 29us/step - loss: 0.0617 - accuracy: 0.9824 - val_loss: 0.0478 - val_accuracy: 0.9947\n",
            "Epoch 18/30\n",
            "119305/119305 [==============================] - 3s 29us/step - loss: 0.0571 - accuracy: 0.9838 - val_loss: 0.0417 - val_accuracy: 0.9950\n",
            "Epoch 19/30\n",
            "119305/119305 [==============================] - 3s 29us/step - loss: 0.0504 - accuracy: 0.9858 - val_loss: 0.0378 - val_accuracy: 0.9960\n",
            "Epoch 20/30\n",
            "119305/119305 [==============================] - 3s 29us/step - loss: 0.0471 - accuracy: 0.9869 - val_loss: 0.0352 - val_accuracy: 0.9958\n",
            "Epoch 21/30\n",
            "119305/119305 [==============================] - 3s 29us/step - loss: 0.0433 - accuracy: 0.9879 - val_loss: 0.0326 - val_accuracy: 0.9961\n",
            "Epoch 22/30\n",
            "119305/119305 [==============================] - 3s 29us/step - loss: 0.0390 - accuracy: 0.9892 - val_loss: 0.0289 - val_accuracy: 0.9965\n",
            "Epoch 23/30\n",
            "119305/119305 [==============================] - 3s 29us/step - loss: 0.0374 - accuracy: 0.9896 - val_loss: 0.0262 - val_accuracy: 0.9975\n",
            "Epoch 24/30\n",
            "119305/119305 [==============================] - 3s 29us/step - loss: 0.0347 - accuracy: 0.9900 - val_loss: 0.0247 - val_accuracy: 0.9977\n",
            "Epoch 25/30\n",
            "119305/119305 [==============================] - 3s 29us/step - loss: 0.0322 - accuracy: 0.9912 - val_loss: 0.0225 - val_accuracy: 0.9970\n",
            "Epoch 26/30\n",
            "119305/119305 [==============================] - 3s 29us/step - loss: 0.0303 - accuracy: 0.9916 - val_loss: 0.0182 - val_accuracy: 0.9991\n",
            "Epoch 27/30\n",
            "119305/119305 [==============================] - 3s 28us/step - loss: 0.0279 - accuracy: 0.9924 - val_loss: 0.0195 - val_accuracy: 0.9975\n",
            "Epoch 28/30\n",
            "119305/119305 [==============================] - 3s 29us/step - loss: 0.0260 - accuracy: 0.9927 - val_loss: 0.0176 - val_accuracy: 0.9984\n",
            "Epoch 29/30\n",
            "119305/119305 [==============================] - 3s 29us/step - loss: 0.0244 - accuracy: 0.9933 - val_loss: 0.0153 - val_accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "119305/119305 [==============================] - 3s 29us/step - loss: 0.0249 - accuracy: 0.9933 - val_loss: 0.0141 - val_accuracy: 0.9988\n",
            "[[ 994    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0  617    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0 1127    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    1  958    1    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0 1340    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0 2406    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0  731    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0  343    3    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4396    2    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0   10 4142    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0  182    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0    0    0  774    0    0\n",
            "     0    0    0    0    0    0    0    1]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0 3387    0\n",
            "     0    0    0    0    0    3    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0  616\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  1920    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0  229    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0 1394    2    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0  226    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    2    0    0    0    0    0\n",
            "     0    0    0    0  985    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    2    0    0    0    0    0\n",
            "     0    0    0    0    0  742    2    0]\n",
            " [   0    0    0    0    0    0    0    0    0    4    0    0    0    0\n",
            "     0    0    0    0    0    0  687    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    1 1596]]\n",
            "0.9988265665336775\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       994\n",
            "           1       1.00      1.00      1.00       617\n",
            "           2       1.00      1.00      1.00      1127\n",
            "           3       1.00      1.00      1.00       960\n",
            "           4       1.00      1.00      1.00      1340\n",
            "           5       1.00      1.00      1.00      2406\n",
            "           6       1.00      1.00      1.00       731\n",
            "           7       1.00      0.99      1.00       346\n",
            "           8       1.00      1.00      1.00      4398\n",
            "           9       1.00      1.00      1.00      4152\n",
            "          10       1.00      1.00      1.00       182\n",
            "          11       1.00      1.00      1.00       776\n",
            "          12       1.00      1.00      1.00      3390\n",
            "          13       1.00      1.00      1.00       616\n",
            "          14       1.00      1.00      1.00      1920\n",
            "          15       1.00      1.00      1.00       229\n",
            "          16       1.00      1.00      1.00      1396\n",
            "          17       0.99      1.00      1.00       226\n",
            "          18       1.00      1.00      1.00       987\n",
            "          19       1.00      0.99      1.00       746\n",
            "          20       1.00      0.99      0.99       691\n",
            "          21       1.00      1.00      1.00      1597\n",
            "\n",
            "    accuracy                           1.00     29827\n",
            "   macro avg       1.00      1.00      1.00     29827\n",
            "weighted avg       1.00      1.00      1.00     29827\n",
            "\n",
            "512\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 200, 3, 16)        160       \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 200, 3, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 100, 1, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1024)              1639424   \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 22)                22550     \n",
            "=================================================================\n",
            "Total params: 1,662,134\n",
            "Trainable params: 1,662,134\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 119305 samples, validate on 29827 samples\n",
            "Epoch 1/30\n",
            "119305/119305 [==============================] - 3s 24us/step - loss: 1.7189 - accuracy: 0.4760 - val_loss: 1.2299 - val_accuracy: 0.6612\n",
            "Epoch 2/30\n",
            "119305/119305 [==============================] - 2s 21us/step - loss: 1.0357 - accuracy: 0.6742 - val_loss: 0.8598 - val_accuracy: 0.7725\n",
            "Epoch 3/30\n",
            "119305/119305 [==============================] - 3s 21us/step - loss: 0.7643 - accuracy: 0.7575 - val_loss: 0.6580 - val_accuracy: 0.8404\n",
            "Epoch 4/30\n",
            "119305/119305 [==============================] - 2s 21us/step - loss: 0.5973 - accuracy: 0.8099 - val_loss: 0.5301 - val_accuracy: 0.8672\n",
            "Epoch 5/30\n",
            "119305/119305 [==============================] - 2s 21us/step - loss: 0.4940 - accuracy: 0.8435 - val_loss: 0.4392 - val_accuracy: 0.8957\n",
            "Epoch 6/30\n",
            "119305/119305 [==============================] - 2s 20us/step - loss: 0.4132 - accuracy: 0.8692 - val_loss: 0.3722 - val_accuracy: 0.9150\n",
            "Epoch 7/30\n",
            "119305/119305 [==============================] - 2s 21us/step - loss: 0.3496 - accuracy: 0.8912 - val_loss: 0.3250 - val_accuracy: 0.9236\n",
            "Epoch 8/30\n",
            "119305/119305 [==============================] - 2s 20us/step - loss: 0.3049 - accuracy: 0.9052 - val_loss: 0.2748 - val_accuracy: 0.9458\n",
            "Epoch 9/30\n",
            "119305/119305 [==============================] - 2s 20us/step - loss: 0.2723 - accuracy: 0.9159 - val_loss: 0.2447 - val_accuracy: 0.9528\n",
            "Epoch 10/30\n",
            "119305/119305 [==============================] - 2s 20us/step - loss: 0.2364 - accuracy: 0.9273 - val_loss: 0.2104 - val_accuracy: 0.9641\n",
            "Epoch 11/30\n",
            "119305/119305 [==============================] - 2s 20us/step - loss: 0.2106 - accuracy: 0.9359 - val_loss: 0.1925 - val_accuracy: 0.9654\n",
            "Epoch 12/30\n",
            "119305/119305 [==============================] - 2s 20us/step - loss: 0.1884 - accuracy: 0.9434 - val_loss: 0.1696 - val_accuracy: 0.9710\n",
            "Epoch 13/30\n",
            "119305/119305 [==============================] - 2s 20us/step - loss: 0.1714 - accuracy: 0.9496 - val_loss: 0.1521 - val_accuracy: 0.9754\n",
            "Epoch 14/30\n",
            "119305/119305 [==============================] - 2s 21us/step - loss: 0.1530 - accuracy: 0.9553 - val_loss: 0.1431 - val_accuracy: 0.9730\n",
            "Epoch 15/30\n",
            "119305/119305 [==============================] - 2s 21us/step - loss: 0.1376 - accuracy: 0.9597 - val_loss: 0.1262 - val_accuracy: 0.9800\n",
            "Epoch 16/30\n",
            "119305/119305 [==============================] - 2s 21us/step - loss: 0.1261 - accuracy: 0.9643 - val_loss: 0.1132 - val_accuracy: 0.9822\n",
            "Epoch 17/30\n",
            "119305/119305 [==============================] - 2s 21us/step - loss: 0.1154 - accuracy: 0.9666 - val_loss: 0.1036 - val_accuracy: 0.9846\n",
            "Epoch 18/30\n",
            "119305/119305 [==============================] - 2s 20us/step - loss: 0.1088 - accuracy: 0.9687 - val_loss: 0.0908 - val_accuracy: 0.9884\n",
            "Epoch 19/30\n",
            "119305/119305 [==============================] - 2s 20us/step - loss: 0.0972 - accuracy: 0.9720 - val_loss: 0.0842 - val_accuracy: 0.9890\n",
            "Epoch 20/30\n",
            "119305/119305 [==============================] - 2s 20us/step - loss: 0.0966 - accuracy: 0.9721 - val_loss: 0.0874 - val_accuracy: 0.9858\n",
            "Epoch 21/30\n",
            "119305/119305 [==============================] - 2s 20us/step - loss: 0.0852 - accuracy: 0.9758 - val_loss: 0.0751 - val_accuracy: 0.9892\n",
            "Epoch 22/30\n",
            "119305/119305 [==============================] - 2s 20us/step - loss: 0.0791 - accuracy: 0.9776 - val_loss: 0.0688 - val_accuracy: 0.9907\n",
            "Epoch 23/30\n",
            "119305/119305 [==============================] - 2s 21us/step - loss: 0.0746 - accuracy: 0.9792 - val_loss: 0.0643 - val_accuracy: 0.9914\n",
            "Epoch 24/30\n",
            "119305/119305 [==============================] - 2s 20us/step - loss: 0.0716 - accuracy: 0.9798 - val_loss: 0.0587 - val_accuracy: 0.9935\n",
            "Epoch 25/30\n",
            "119305/119305 [==============================] - 2s 21us/step - loss: 0.0632 - accuracy: 0.9829 - val_loss: 0.0546 - val_accuracy: 0.9931\n",
            "Epoch 26/30\n",
            "119305/119305 [==============================] - 2s 20us/step - loss: 0.0610 - accuracy: 0.9830 - val_loss: 0.0494 - val_accuracy: 0.9941\n",
            "Epoch 27/30\n",
            "119305/119305 [==============================] - 2s 20us/step - loss: 0.0566 - accuracy: 0.9847 - val_loss: 0.0471 - val_accuracy: 0.9954\n",
            "Epoch 28/30\n",
            "119305/119305 [==============================] - 2s 20us/step - loss: 0.0522 - accuracy: 0.9858 - val_loss: 0.0443 - val_accuracy: 0.9937\n",
            "Epoch 29/30\n",
            "119305/119305 [==============================] - 2s 20us/step - loss: 0.0478 - accuracy: 0.9868 - val_loss: 0.0411 - val_accuracy: 0.9956\n",
            "Epoch 30/30\n",
            "119305/119305 [==============================] - 2s 20us/step - loss: 0.0440 - accuracy: 0.9883 - val_loss: 0.0391 - val_accuracy: 0.9953\n",
            "[[ 994    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0  614    0    0    0    0    0    0    0    3    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0 1126    0    0    0    0    0    0    1    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0  958    1    0    0    0    0    1    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0 1339    1    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0 2397    0    0    0    0    0    5    0    0\n",
            "     0    0    0    0    0    0    0    4]\n",
            " [   0    0    0    0    0    0  731    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0  336   10    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4382   15    0    0    0    0\n",
            "     0    0    0    0    1    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4152    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0  182    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0    0    0  767    0    0\n",
            "     0    0    0    0    0    0    0    4]\n",
            " [   3    0    0    0    0    0    0    0    2    0    0    0 3381    0\n",
            "     0    0    0    0    0    4    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0  616\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    3    0    0    0    0    0    0    0    0    0    0    0\n",
            "  1917    0    0    0    0    0    0    0]\n",
            " [   0    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0  228    0    0    0    0    0    0]\n",
            " [   0    1    0    0    0    0    0    0    0   28    0    0    0    0\n",
            "     0    0 1365    2    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0  226    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0  987    0    0    0]\n",
            " [   3    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0  743    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0   39    0    0    0    0\n",
            "     0    0    0    0    0    0  652    0]\n",
            " [   0    0    0    0    0    0    0    0    3    0    0    0    0    0\n",
            "     0    0    0    0    0    0    1 1593]]\n",
            "0.9952727394642438\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       994\n",
            "           1       1.00      1.00      1.00       617\n",
            "           2       1.00      1.00      1.00      1127\n",
            "           3       1.00      1.00      1.00       960\n",
            "           4       1.00      1.00      1.00      1340\n",
            "           5       1.00      1.00      1.00      2406\n",
            "           6       0.99      1.00      1.00       731\n",
            "           7       1.00      0.97      0.99       346\n",
            "           8       1.00      1.00      1.00      4398\n",
            "           9       0.98      1.00      0.99      4152\n",
            "          10       1.00      1.00      1.00       182\n",
            "          11       0.99      0.99      0.99       776\n",
            "          12       1.00      1.00      1.00      3390\n",
            "          13       1.00      1.00      1.00       616\n",
            "          14       1.00      1.00      1.00      1920\n",
            "          15       1.00      1.00      1.00       229\n",
            "          16       1.00      0.98      0.99      1396\n",
            "          17       0.99      1.00      1.00       226\n",
            "          18       1.00      1.00      1.00       987\n",
            "          19       0.99      1.00      1.00       746\n",
            "          20       1.00      0.94      0.97       691\n",
            "          21       1.00      1.00      1.00      1597\n",
            "\n",
            "    accuracy                           1.00     29827\n",
            "   macro avg       1.00      0.99      0.99     29827\n",
            "weighted avg       1.00      1.00      1.00     29827\n",
            "\n",
            "1024\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 200, 3, 16)        160       \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 200, 3, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 100, 1, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1024)              1639424   \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 22)                22550     \n",
            "=================================================================\n",
            "Total params: 1,662,134\n",
            "Trainable params: 1,662,134\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 119305 samples, validate on 29827 samples\n",
            "Epoch 1/30\n",
            "119305/119305 [==============================] - 2s 21us/step - loss: 1.9436 - accuracy: 0.4139 - val_loss: 1.4783 - val_accuracy: 0.5948\n",
            "Epoch 2/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 1.2524 - accuracy: 0.6173 - val_loss: 1.0871 - val_accuracy: 0.6992\n",
            "Epoch 3/30\n",
            "119305/119305 [==============================] - 2s 16us/step - loss: 0.9654 - accuracy: 0.6988 - val_loss: 0.8625 - val_accuracy: 0.7715\n",
            "Epoch 4/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.7837 - accuracy: 0.7531 - val_loss: 0.7089 - val_accuracy: 0.8234\n",
            "Epoch 5/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.6564 - accuracy: 0.7934 - val_loss: 0.6027 - val_accuracy: 0.8584\n",
            "Epoch 6/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.5593 - accuracy: 0.8267 - val_loss: 0.5185 - val_accuracy: 0.8809\n",
            "Epoch 7/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.4913 - accuracy: 0.8461 - val_loss: 0.4533 - val_accuracy: 0.8980\n",
            "Epoch 8/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.4308 - accuracy: 0.8660 - val_loss: 0.4038 - val_accuracy: 0.9058\n",
            "Epoch 9/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.3851 - accuracy: 0.8813 - val_loss: 0.3587 - val_accuracy: 0.9193\n",
            "Epoch 10/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.3448 - accuracy: 0.8944 - val_loss: 0.3243 - val_accuracy: 0.9301\n",
            "Epoch 11/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.3119 - accuracy: 0.9054 - val_loss: 0.2933 - val_accuracy: 0.9389\n",
            "Epoch 12/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.2822 - accuracy: 0.9141 - val_loss: 0.2694 - val_accuracy: 0.9461\n",
            "Epoch 13/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.2578 - accuracy: 0.9229 - val_loss: 0.2387 - val_accuracy: 0.9562\n",
            "Epoch 14/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.2363 - accuracy: 0.9295 - val_loss: 0.2235 - val_accuracy: 0.9608\n",
            "Epoch 15/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.2182 - accuracy: 0.9353 - val_loss: 0.2093 - val_accuracy: 0.9611\n",
            "Epoch 16/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.2003 - accuracy: 0.9410 - val_loss: 0.1930 - val_accuracy: 0.9667\n",
            "Epoch 17/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.1861 - accuracy: 0.9452 - val_loss: 0.1786 - val_accuracy: 0.9679\n",
            "Epoch 18/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.1717 - accuracy: 0.9500 - val_loss: 0.1599 - val_accuracy: 0.9762\n",
            "Epoch 19/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.1582 - accuracy: 0.9539 - val_loss: 0.1474 - val_accuracy: 0.9779\n",
            "Epoch 20/30\n",
            "119305/119305 [==============================] - 2s 16us/step - loss: 0.1485 - accuracy: 0.9571 - val_loss: 0.1377 - val_accuracy: 0.9781\n",
            "Epoch 21/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.1371 - accuracy: 0.9614 - val_loss: 0.1294 - val_accuracy: 0.9806\n",
            "Epoch 22/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.1301 - accuracy: 0.9627 - val_loss: 0.1203 - val_accuracy: 0.9818\n",
            "Epoch 23/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.1202 - accuracy: 0.9659 - val_loss: 0.1106 - val_accuracy: 0.9857\n",
            "Epoch 24/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.1131 - accuracy: 0.9683 - val_loss: 0.1045 - val_accuracy: 0.9867\n",
            "Epoch 25/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.1066 - accuracy: 0.9706 - val_loss: 0.0991 - val_accuracy: 0.9856\n",
            "Epoch 26/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.0988 - accuracy: 0.9726 - val_loss: 0.0917 - val_accuracy: 0.9874\n",
            "Epoch 27/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.0927 - accuracy: 0.9746 - val_loss: 0.0823 - val_accuracy: 0.9913\n",
            "Epoch 28/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.0887 - accuracy: 0.9756 - val_loss: 0.0825 - val_accuracy: 0.9882\n",
            "Epoch 29/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.0837 - accuracy: 0.9773 - val_loss: 0.0753 - val_accuracy: 0.9908\n",
            "Epoch 30/30\n",
            "119305/119305 [==============================] - 2s 17us/step - loss: 0.0777 - accuracy: 0.9792 - val_loss: 0.0703 - val_accuracy: 0.9914\n",
            "[[ 993    0    0    0    0    0    0    0    1    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0  612    0    0    0    0    0    1    0    4    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0 1126    0    0    0    0    1    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0  955    3    0    0    0    2    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0 1319    2    0    0    0   12    0    0    0    7\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0 2389    0    0    3    6    0    0    0    0\n",
            "     0    0    0    5    0    0    0    3]\n",
            " [   0    0    0    0    0    0  721    0   10    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   1    0    2    0    0    0    0  323   15    0    0    0    0    5\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4381   15    0    0    0    2\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   8    0    0    0    0    0    0    0   20 4124    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0  182    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    6    6    0    0    0    0  753    0    0\n",
            "     0    0    0    0    0    0    0   11]\n",
            " [   2    0    0    0    0    0    0    0    8    0    0    0 3375    0\n",
            "     0    0    0    0    0    5    0    0]\n",
            " [   0    0    0    0    0    1    0    0    0    0    0    0    0  614\n",
            "     0    0    1    0    0    0    0    0]\n",
            " [   0    0    6    0    0    0    0    0    3    0    0    0    0    0\n",
            "  1911    0    0    0    0    0    0    0]\n",
            " [   0    2    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0  227    0    0    0    0    0    0]\n",
            " [   0    3    1    0    0    0    0    0    4   19    0    0    0    0\n",
            "     0    0 1367    2    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0  226    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    5    1    0    0    0    0\n",
            "     0    0    0    0  981    0    0    0]\n",
            " [   2    0    0    0    0    0    0    0    4    0    0    0    0    0\n",
            "     0    0    0    0    0  740    0    0]\n",
            " [   0    0    0    0    0    0    0    0    1   32    0    0    0    0\n",
            "     0    0    0    0    0    0  658    0]\n",
            " [   0    0    0    0    0    0    0    0    1    4    0    0    0    0\n",
            "     0    0    0    0    0    0    0 1592]]\n",
            "0.9913501190196802\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       994\n",
            "           1       0.99      0.99      0.99       617\n",
            "           2       0.99      1.00      1.00      1127\n",
            "           3       1.00      0.99      1.00       960\n",
            "           4       1.00      0.98      0.99      1340\n",
            "           5       1.00      0.99      0.99      2406\n",
            "           6       0.99      0.99      0.99       731\n",
            "           7       0.99      0.93      0.96       346\n",
            "           8       0.98      1.00      0.99      4398\n",
            "           9       0.98      0.99      0.99      4152\n",
            "          10       1.00      1.00      1.00       182\n",
            "          11       1.00      0.97      0.98       776\n",
            "          12       1.00      1.00      1.00      3390\n",
            "          13       0.98      1.00      0.99       616\n",
            "          14       1.00      1.00      1.00      1920\n",
            "          15       1.00      0.99      1.00       229\n",
            "          16       1.00      0.98      0.99      1396\n",
            "          17       0.97      1.00      0.98       226\n",
            "          18       1.00      0.99      1.00       987\n",
            "          19       0.99      0.99      0.99       746\n",
            "          20       1.00      0.95      0.98       691\n",
            "          21       0.99      1.00      0.99      1597\n",
            "\n",
            "    accuracy                           0.99     29827\n",
            "   macro avg       0.99      0.99      0.99     29827\n",
            "weighted avg       0.99      0.99      0.99     29827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdI6OL1HgNwa",
        "colab_type": "code",
        "outputId": "b648da07-66b9-41de-d5b2-8d4a89281df7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras import optimizers\n",
        "\n",
        "fruits = [0.0001,0.001,0.01,0.1,1.0]\n",
        "for x in fruits:\n",
        "  print(x)\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(filters=16, kernel_size=(3,3), padding='same', activation='relu',input_shape=X_train[0].shape))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(MaxPooling2D(pool_size=2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(22, activation='softmax'))\n",
        "  model.summary() \n",
        "  sgd = optimizers.adam(lr=x)\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "  history = model.fit(X_train, y_train, epochs =30, validation_data= (X_test, y_test),batch_size=64, verbose=1)  \n",
        "  y_pred = model.predict_classes(X_test)\n",
        "  mat = confusion_matrix(y_test, y_pred)\n",
        "  print(confusion_matrix(y_test, y_pred))\n",
        "  print(accuracy_score(y_test,y_pred))\n",
        "  print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0001\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 200, 3, 16)        160       \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 200, 3, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 100, 1, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1024)              1639424   \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 22)                22550     \n",
            "=================================================================\n",
            "Total params: 1,662,134\n",
            "Trainable params: 1,662,134\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 119305 samples, validate on 29827 samples\n",
            "Epoch 1/30\n",
            "119305/119305 [==============================] - 10s 84us/step - loss: 1.1011 - accuracy: 0.6590 - val_loss: 0.5804 - val_accuracy: 0.8558\n",
            "Epoch 2/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 0.4608 - accuracy: 0.8529 - val_loss: 0.3358 - val_accuracy: 0.9178\n",
            "Epoch 3/30\n",
            "119305/119305 [==============================] - 10s 80us/step - loss: 0.2910 - accuracy: 0.9082 - val_loss: 0.2270 - val_accuracy: 0.9533\n",
            "Epoch 4/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.2034 - accuracy: 0.9365 - val_loss: 0.1598 - val_accuracy: 0.9704\n",
            "Epoch 5/30\n",
            "119305/119305 [==============================] - 10s 80us/step - loss: 0.1530 - accuracy: 0.9529 - val_loss: 0.1177 - val_accuracy: 0.9794\n",
            "Epoch 6/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.1174 - accuracy: 0.9642 - val_loss: 0.0922 - val_accuracy: 0.9839\n",
            "Epoch 7/30\n",
            "119305/119305 [==============================] - 10s 80us/step - loss: 0.0940 - accuracy: 0.9713 - val_loss: 0.0700 - val_accuracy: 0.9883\n",
            "Epoch 8/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.0786 - accuracy: 0.9760 - val_loss: 0.0586 - val_accuracy: 0.9923\n",
            "Epoch 9/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.0682 - accuracy: 0.9794 - val_loss: 0.0470 - val_accuracy: 0.9923\n",
            "Epoch 10/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.0572 - accuracy: 0.9827 - val_loss: 0.0396 - val_accuracy: 0.9945\n",
            "Epoch 11/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.0485 - accuracy: 0.9851 - val_loss: 0.0402 - val_accuracy: 0.9932\n",
            "Epoch 12/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.0439 - accuracy: 0.9868 - val_loss: 0.0311 - val_accuracy: 0.9972\n",
            "Epoch 13/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.0394 - accuracy: 0.9877 - val_loss: 0.0292 - val_accuracy: 0.9958\n",
            "Epoch 14/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.0352 - accuracy: 0.9893 - val_loss: 0.0214 - val_accuracy: 0.9981\n",
            "Epoch 15/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.0319 - accuracy: 0.9900 - val_loss: 0.0222 - val_accuracy: 0.9974\n",
            "Epoch 16/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.0295 - accuracy: 0.9911 - val_loss: 0.0170 - val_accuracy: 0.9983\n",
            "Epoch 17/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 0.0258 - accuracy: 0.9925 - val_loss: 0.0186 - val_accuracy: 0.9975\n",
            "Epoch 18/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 0.0252 - accuracy: 0.9924 - val_loss: 0.0166 - val_accuracy: 0.9985\n",
            "Epoch 19/30\n",
            "119305/119305 [==============================] - 10s 84us/step - loss: 0.0230 - accuracy: 0.9928 - val_loss: 0.0149 - val_accuracy: 0.9981\n",
            "Epoch 20/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.0220 - accuracy: 0.9934 - val_loss: 0.0112 - val_accuracy: 0.9991\n",
            "Epoch 21/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.0215 - accuracy: 0.9934 - val_loss: 0.0101 - val_accuracy: 0.9994\n",
            "Epoch 22/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 0.0107 - val_accuracy: 0.9989\n",
            "Epoch 23/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.0137 - val_accuracy: 0.9974\n",
            "Epoch 24/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.0180 - accuracy: 0.9946 - val_loss: 0.0076 - val_accuracy: 0.9994\n",
            "Epoch 25/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.0163 - accuracy: 0.9950 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
            "Epoch 26/30\n",
            "119305/119305 [==============================] - 10s 80us/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.0074 - val_accuracy: 0.9992\n",
            "Epoch 27/30\n",
            "119305/119305 [==============================] - 10s 83us/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.0062 - val_accuracy: 0.9993\n",
            "Epoch 28/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 0.0154 - accuracy: 0.9950 - val_loss: 0.0077 - val_accuracy: 0.9990\n",
            "Epoch 29/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.0058 - val_accuracy: 0.9994\n",
            "Epoch 30/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.0052 - val_accuracy: 0.9997\n",
            "[[ 994    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0  617    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0 1127    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    1  959    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    1 1339    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0 2406    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0  731    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0  345    1    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4397    1    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4152    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    1  181    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0  776    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0 3390    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0  616\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  1920    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0  229    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    1    0    0    0    0\n",
            "     0    0 1394    1    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0  226    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0  987    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0  746    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    2    0    0    0    0\n",
            "     0    0    0    0    0    0  689    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0 1597]]\n",
            "0.9996982599658027\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       994\n",
            "           1       1.00      1.00      1.00       617\n",
            "           2       1.00      1.00      1.00      1127\n",
            "           3       1.00      1.00      1.00       960\n",
            "           4       1.00      1.00      1.00      1340\n",
            "           5       1.00      1.00      1.00      2406\n",
            "           6       1.00      1.00      1.00       731\n",
            "           7       1.00      1.00      1.00       346\n",
            "           8       1.00      1.00      1.00      4398\n",
            "           9       1.00      1.00      1.00      4152\n",
            "          10       1.00      0.99      1.00       182\n",
            "          11       1.00      1.00      1.00       776\n",
            "          12       1.00      1.00      1.00      3390\n",
            "          13       1.00      1.00      1.00       616\n",
            "          14       1.00      1.00      1.00      1920\n",
            "          15       1.00      1.00      1.00       229\n",
            "          16       1.00      1.00      1.00      1396\n",
            "          17       1.00      1.00      1.00       226\n",
            "          18       1.00      1.00      1.00       987\n",
            "          19       1.00      1.00      1.00       746\n",
            "          20       1.00      1.00      1.00       691\n",
            "          21       1.00      1.00      1.00      1597\n",
            "\n",
            "    accuracy                           1.00     29827\n",
            "   macro avg       1.00      1.00      1.00     29827\n",
            "weighted avg       1.00      1.00      1.00     29827\n",
            "\n",
            "0.001\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 200, 3, 16)        160       \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 200, 3, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 100, 1, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1024)              1639424   \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 22)                22550     \n",
            "=================================================================\n",
            "Total params: 1,662,134\n",
            "Trainable params: 1,662,134\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 119305 samples, validate on 29827 samples\n",
            "Epoch 1/30\n",
            "119305/119305 [==============================] - 10s 83us/step - loss: 0.5725 - accuracy: 0.8150 - val_loss: 0.2201 - val_accuracy: 0.9394\n",
            "Epoch 2/30\n",
            "119305/119305 [==============================] - 9s 80us/step - loss: 0.2022 - accuracy: 0.9326 - val_loss: 0.1084 - val_accuracy: 0.9734\n",
            "Epoch 3/30\n",
            "119305/119305 [==============================] - 10s 80us/step - loss: 0.1387 - accuracy: 0.9531 - val_loss: 0.0662 - val_accuracy: 0.9871\n",
            "Epoch 4/30\n",
            "119305/119305 [==============================] - 10s 80us/step - loss: 0.1064 - accuracy: 0.9639 - val_loss: 0.0514 - val_accuracy: 0.9867\n",
            "Epoch 5/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.0879 - accuracy: 0.9701 - val_loss: 0.0403 - val_accuracy: 0.9902\n",
            "Epoch 6/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.0750 - accuracy: 0.9740 - val_loss: 0.0345 - val_accuracy: 0.9920\n",
            "Epoch 7/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.0673 - accuracy: 0.9773 - val_loss: 0.0243 - val_accuracy: 0.9942\n",
            "Epoch 8/30\n",
            "119305/119305 [==============================] - 10s 80us/step - loss: 0.0614 - accuracy: 0.9788 - val_loss: 0.0206 - val_accuracy: 0.9947\n",
            "Epoch 9/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.0566 - accuracy: 0.9815 - val_loss: 0.0158 - val_accuracy: 0.9968\n",
            "Epoch 10/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.0514 - accuracy: 0.9829 - val_loss: 0.0206 - val_accuracy: 0.9963\n",
            "Epoch 11/30\n",
            "119305/119305 [==============================] - 10s 80us/step - loss: 0.0500 - accuracy: 0.9835 - val_loss: 0.0119 - val_accuracy: 0.9971\n",
            "Epoch 12/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.0478 - accuracy: 0.9842 - val_loss: 0.0160 - val_accuracy: 0.9966\n",
            "Epoch 13/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.0471 - accuracy: 0.9851 - val_loss: 0.0164 - val_accuracy: 0.9961\n",
            "Epoch 14/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.0391 - accuracy: 0.9871 - val_loss: 0.0105 - val_accuracy: 0.9976\n",
            "Epoch 15/30\n",
            "119305/119305 [==============================] - 9s 80us/step - loss: 0.0430 - accuracy: 0.9861 - val_loss: 0.0160 - val_accuracy: 0.9948\n",
            "Epoch 16/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.0412 - accuracy: 0.9868 - val_loss: 0.0078 - val_accuracy: 0.9989\n",
            "Epoch 17/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.0377 - accuracy: 0.9883 - val_loss: 0.0078 - val_accuracy: 0.9979\n",
            "Epoch 18/30\n",
            "119305/119305 [==============================] - 9s 78us/step - loss: 0.0360 - accuracy: 0.9888 - val_loss: 0.0051 - val_accuracy: 0.9989\n",
            "Epoch 19/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.0387 - accuracy: 0.9882 - val_loss: 0.0067 - val_accuracy: 0.9990\n",
            "Epoch 20/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.0344 - accuracy: 0.9895 - val_loss: 0.0112 - val_accuracy: 0.9969\n",
            "Epoch 21/30\n",
            "119305/119305 [==============================] - 10s 83us/step - loss: 0.0381 - accuracy: 0.9883 - val_loss: 0.0063 - val_accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "119305/119305 [==============================] - 10s 80us/step - loss: 0.0338 - accuracy: 0.9900 - val_loss: 0.0089 - val_accuracy: 0.9976\n",
            "Epoch 23/30\n",
            "119305/119305 [==============================] - 10s 80us/step - loss: 0.0334 - accuracy: 0.9897 - val_loss: 0.0068 - val_accuracy: 0.9981\n",
            "Epoch 24/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.0332 - accuracy: 0.9899 - val_loss: 0.0070 - val_accuracy: 0.9980\n",
            "Epoch 25/30\n",
            "119305/119305 [==============================] - 10s 80us/step - loss: 0.0316 - accuracy: 0.9903 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
            "Epoch 26/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.0341 - accuracy: 0.9899 - val_loss: 0.0031 - val_accuracy: 0.9996\n",
            "Epoch 27/30\n",
            "119305/119305 [==============================] - 10s 80us/step - loss: 0.0316 - accuracy: 0.9908 - val_loss: 0.0047 - val_accuracy: 0.9990\n",
            "Epoch 28/30\n",
            "119305/119305 [==============================] - 10s 80us/step - loss: 0.0325 - accuracy: 0.9908 - val_loss: 0.0040 - val_accuracy: 0.9991\n",
            "Epoch 29/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.0302 - accuracy: 0.9916 - val_loss: 0.0041 - val_accuracy: 0.9992\n",
            "Epoch 30/30\n",
            "119305/119305 [==============================] - 9s 79us/step - loss: 0.0305 - accuracy: 0.9911 - val_loss: 0.0029 - val_accuracy: 0.9995\n",
            "[[ 994    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0  616    1    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0 1127    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    1  959    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0 1340    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0 2406    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0  731    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0  345    0    0    0    0    0    0\n",
            "     0    0    0    0    0    1    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4395    1    0    0    0    0\n",
            "     0    0    0    0    0    2    0    0]\n",
            " [   0    0    0    0    0    0    0    0    2 4150    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0  182    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0  776    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0 3390    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0  616\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  1919    0    0    0    0    0    1    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    1    0    0\n",
            "     0  227    1    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    1    0    0    0    0    0\n",
            "     0    0 1394    1    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0  226    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0  986    1    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0  746    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0  691    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    1 1596]]\n",
            "0.9994970999430046\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       994\n",
            "           1       1.00      1.00      1.00       617\n",
            "           2       1.00      1.00      1.00      1127\n",
            "           3       1.00      1.00      1.00       960\n",
            "           4       1.00      1.00      1.00      1340\n",
            "           5       1.00      1.00      1.00      2406\n",
            "           6       1.00      1.00      1.00       731\n",
            "           7       1.00      1.00      1.00       346\n",
            "           8       1.00      1.00      1.00      4398\n",
            "           9       1.00      1.00      1.00      4152\n",
            "          10       1.00      1.00      1.00       182\n",
            "          11       1.00      1.00      1.00       776\n",
            "          12       1.00      1.00      1.00      3390\n",
            "          13       1.00      1.00      1.00       616\n",
            "          14       1.00      1.00      1.00      1920\n",
            "          15       1.00      0.99      1.00       229\n",
            "          16       1.00      1.00      1.00      1396\n",
            "          17       1.00      1.00      1.00       226\n",
            "          18       1.00      1.00      1.00       987\n",
            "          19       0.99      1.00      1.00       746\n",
            "          20       1.00      1.00      1.00       691\n",
            "          21       1.00      1.00      1.00      1597\n",
            "\n",
            "    accuracy                           1.00     29827\n",
            "   macro avg       1.00      1.00      1.00     29827\n",
            "weighted avg       1.00      1.00      1.00     29827\n",
            "\n",
            "0.01\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 200, 3, 16)        160       \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 200, 3, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 100, 1, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1024)              1639424   \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 22)                22550     \n",
            "=================================================================\n",
            "Total params: 1,662,134\n",
            "Trainable params: 1,662,134\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 119305 samples, validate on 29827 samples\n",
            "Epoch 1/30\n",
            "119305/119305 [==============================] - 10s 86us/step - loss: 0.9250 - accuracy: 0.7135 - val_loss: 0.4640 - val_accuracy: 0.8627\n",
            "Epoch 2/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.6920 - accuracy: 0.7840 - val_loss: 0.3767 - val_accuracy: 0.8802\n",
            "Epoch 3/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 0.6706 - accuracy: 0.7944 - val_loss: 0.4243 - val_accuracy: 0.8681\n",
            "Epoch 4/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.6607 - accuracy: 0.8003 - val_loss: 0.3778 - val_accuracy: 0.8796\n",
            "Epoch 5/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 0.6497 - accuracy: 0.8051 - val_loss: 0.3353 - val_accuracy: 0.8889\n",
            "Epoch 6/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 0.6615 - accuracy: 0.8041 - val_loss: 0.4222 - val_accuracy: 0.8718\n",
            "Epoch 7/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 0.6925 - accuracy: 0.7994 - val_loss: 0.3638 - val_accuracy: 0.8877\n",
            "Epoch 8/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 0.6864 - accuracy: 0.8021 - val_loss: 0.3990 - val_accuracy: 0.8760\n",
            "Epoch 9/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 0.6752 - accuracy: 0.8049 - val_loss: 0.3449 - val_accuracy: 0.8923\n",
            "Epoch 10/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.6696 - accuracy: 0.8055 - val_loss: 0.3693 - val_accuracy: 0.8837\n",
            "Epoch 11/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.6826 - accuracy: 0.8045 - val_loss: 0.3564 - val_accuracy: 0.8897\n",
            "Epoch 12/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 0.6661 - accuracy: 0.8100 - val_loss: 0.3421 - val_accuracy: 0.8925\n",
            "Epoch 13/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.6950 - accuracy: 0.8039 - val_loss: 0.3339 - val_accuracy: 0.8949\n",
            "Epoch 14/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.7093 - accuracy: 0.8029 - val_loss: 0.3601 - val_accuracy: 0.8900\n",
            "Epoch 15/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.7068 - accuracy: 0.8024 - val_loss: 0.3227 - val_accuracy: 0.8968\n",
            "Epoch 16/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 0.7171 - accuracy: 0.8019 - val_loss: 0.3802 - val_accuracy: 0.8864\n",
            "Epoch 17/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 0.7589 - accuracy: 0.7927 - val_loss: 0.3524 - val_accuracy: 0.8914\n",
            "Epoch 18/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.6935 - accuracy: 0.8072 - val_loss: 0.3292 - val_accuracy: 0.8993\n",
            "Epoch 19/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.8038 - accuracy: 0.7870 - val_loss: 0.4481 - val_accuracy: 0.8611\n",
            "Epoch 20/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.7274 - accuracy: 0.8013 - val_loss: 0.3538 - val_accuracy: 0.8910\n",
            "Epoch 21/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.7039 - accuracy: 0.8038 - val_loss: 0.3554 - val_accuracy: 0.8895\n",
            "Epoch 22/30\n",
            "119305/119305 [==============================] - 10s 83us/step - loss: 0.7378 - accuracy: 0.7963 - val_loss: 0.3523 - val_accuracy: 0.8907\n",
            "Epoch 23/30\n",
            "119305/119305 [==============================] - 10s 84us/step - loss: 0.7620 - accuracy: 0.7925 - val_loss: 0.3752 - val_accuracy: 0.8828\n",
            "Epoch 24/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.7359 - accuracy: 0.7994 - val_loss: 0.3693 - val_accuracy: 0.8871\n",
            "Epoch 25/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 0.7848 - accuracy: 0.7906 - val_loss: 0.3984 - val_accuracy: 0.8788\n",
            "Epoch 26/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 0.7661 - accuracy: 0.7948 - val_loss: 0.4076 - val_accuracy: 0.8747\n",
            "Epoch 27/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 0.9748 - accuracy: 0.7553 - val_loss: 0.6279 - val_accuracy: 0.8207\n",
            "Epoch 28/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 0.8255 - accuracy: 0.7777 - val_loss: 0.3751 - val_accuracy: 0.8843\n",
            "Epoch 29/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 0.8252 - accuracy: 0.7830 - val_loss: 0.4508 - val_accuracy: 0.8660\n",
            "Epoch 30/30\n",
            "119305/119305 [==============================] - 10s 83us/step - loss: 0.7698 - accuracy: 0.7910 - val_loss: 0.4912 - val_accuracy: 0.8623\n",
            "[[ 902    1    0    0    0    0    0    0    0   88    0    0    0    0\n",
            "     1    0    0    0    0    0    2    0]\n",
            " [   0  517    0    0    0    0    0    0    3   97    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   1    2  966    0    0    0    0    0   16  123    0    0    0    0\n",
            "     0    0   17    0    0    0    2    0]\n",
            " [   0    0    0  825    0    0    0    0   41   84    0    0    0    0\n",
            "     0    0    0    0    1    0    0    9]\n",
            " [   0    0    0    0 1133    0    0    0    9  163    0   33    0    2\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0 2272    0    0    5  128    0    1    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    1    0    0  546    0   28  143    0    6    1    0\n",
            "     0    0    3    0    0    0    0    3]\n",
            " [   0    0    3    0    0    0    0   86   33  176    0    9    0    0\n",
            "     0    0   19    0    0    0    0   20]\n",
            " [   0    0    2    0    1    0    0    0 3866  449    0   12   52    1\n",
            "     3    0    4    0    0    0    4    4]\n",
            " [   0    0    0    0    0    0    0    0    0 4145    0    0    0    0\n",
            "     2    0    3    1    0    1    0    0]\n",
            " [   0    0    0    0   21    0    0    0    0   11  150    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    7    0    3    0   90  162    0  495    4    1\n",
            "     0    0    6    0    0    0    0    8]\n",
            " [   0    0    0    0    0    0    0    0   15  112    0    0 3240    0\n",
            "     0    0    0    0    1    0    0   22]\n",
            " [   0    0    0    7   47    0    0    0  112   37    0  148    2  263\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   3    4    0    0    0    0    0    0    8  146    0    0    0    0\n",
            "  1756    0    3    0    0    0    0    0]\n",
            " [   0    0    0    1    0    0    0    0    0   87    0    0    0    0\n",
            "     0  125    0    0    1   15    0    0]\n",
            " [   1    0    0    0    0    0    0    0    4  344    0    0    0    0\n",
            "     0    0 1045    0    0    0    2    0]\n",
            " [   0    0    0    0    0    0    0    0    6   68    0    0    0    0\n",
            "     0    0    0  152    0    0    0    0]\n",
            " [   0    0    0    1   12    0    0    2   18   77    0    0    1    0\n",
            "     0    0    0    0  854    3    0   19]\n",
            " [   0    0    0    0    0    0    0    0    0   92    0    1    0    0\n",
            "     0    0    0    0    0  653    0    0]\n",
            " [   0    9    3    0    0    0    0    0   23  211    0    0    0    0\n",
            "     1    0   24    0    0    0  420    0]\n",
            " [   0    0    0    0    0    0    0    0   60  158    0   62    7    0\n",
            "     2    0    0    0    0    0    0 1308]]\n",
            "0.8622724377242096\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.91      0.95       994\n",
            "           1       0.97      0.84      0.90       617\n",
            "           2       0.99      0.86      0.92      1127\n",
            "           3       0.99      0.86      0.92       960\n",
            "           4       0.93      0.85      0.88      1340\n",
            "           5       1.00      0.94      0.97      2406\n",
            "           6       0.99      0.75      0.85       731\n",
            "           7       0.98      0.25      0.40       346\n",
            "           8       0.89      0.88      0.89      4398\n",
            "           9       0.58      1.00      0.74      4152\n",
            "          10       1.00      0.82      0.90       182\n",
            "          11       0.65      0.64      0.64       776\n",
            "          12       0.98      0.96      0.97      3390\n",
            "          13       0.99      0.43      0.60       616\n",
            "          14       0.99      0.91      0.95      1920\n",
            "          15       1.00      0.55      0.71       229\n",
            "          16       0.93      0.75      0.83      1396\n",
            "          17       0.99      0.67      0.80       226\n",
            "          18       1.00      0.87      0.93       987\n",
            "          19       0.97      0.88      0.92       746\n",
            "          20       0.98      0.61      0.75       691\n",
            "          21       0.94      0.82      0.87      1597\n",
            "\n",
            "    accuracy                           0.86     29827\n",
            "   macro avg       0.94      0.77      0.83     29827\n",
            "weighted avg       0.90      0.86      0.87     29827\n",
            "\n",
            "0.1\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 200, 3, 16)        160       \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 200, 3, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 100, 1, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1024)              1639424   \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 22)                22550     \n",
            "=================================================================\n",
            "Total params: 1,662,134\n",
            "Trainable params: 1,662,134\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 119305 samples, validate on 29827 samples\n",
            "Epoch 1/30\n",
            "119305/119305 [==============================] - 10s 85us/step - loss: 3.8042 - accuracy: 0.1863 - val_loss: 2.7892 - val_accuracy: 0.1475\n",
            "Epoch 2/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.7791 - accuracy: 0.1436 - val_loss: 2.7769 - val_accuracy: 0.1392\n",
            "Epoch 3/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 2.7793 - accuracy: 0.1437 - val_loss: 2.7783 - val_accuracy: 0.1475\n",
            "Epoch 4/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 2.7792 - accuracy: 0.1413 - val_loss: 2.7798 - val_accuracy: 0.1475\n",
            "Epoch 5/30\n",
            "119305/119305 [==============================] - 10s 83us/step - loss: 2.7789 - accuracy: 0.1434 - val_loss: 2.7890 - val_accuracy: 0.1475\n",
            "Epoch 6/30\n",
            "119305/119305 [==============================] - 10s 83us/step - loss: 2.7797 - accuracy: 0.1424 - val_loss: 2.7777 - val_accuracy: 0.1392\n",
            "Epoch 7/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 2.7787 - accuracy: 0.1438 - val_loss: 2.7783 - val_accuracy: 0.1475\n",
            "Epoch 8/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.7783 - accuracy: 0.1443 - val_loss: 2.7851 - val_accuracy: 0.1475\n",
            "Epoch 9/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 2.7789 - accuracy: 0.1439 - val_loss: 2.7801 - val_accuracy: 0.1392\n",
            "Epoch 10/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.7791 - accuracy: 0.1437 - val_loss: 2.7806 - val_accuracy: 0.1392\n",
            "Epoch 11/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.7797 - accuracy: 0.1423 - val_loss: 2.7769 - val_accuracy: 0.1475\n",
            "Epoch 12/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.7788 - accuracy: 0.1434 - val_loss: 2.7791 - val_accuracy: 0.1392\n",
            "Epoch 13/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.7787 - accuracy: 0.1442 - val_loss: 2.7829 - val_accuracy: 0.1475\n",
            "Epoch 14/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.7783 - accuracy: 0.1441 - val_loss: 2.7743 - val_accuracy: 0.1475\n",
            "Epoch 15/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 2.7786 - accuracy: 0.1445 - val_loss: 2.7794 - val_accuracy: 0.1137\n",
            "Epoch 16/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.7790 - accuracy: 0.1435 - val_loss: 2.7739 - val_accuracy: 0.1475\n",
            "Epoch 17/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.7792 - accuracy: 0.1432 - val_loss: 2.7738 - val_accuracy: 0.1392\n",
            "Epoch 18/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.7789 - accuracy: 0.1443 - val_loss: 2.7759 - val_accuracy: 0.1392\n",
            "Epoch 19/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.7791 - accuracy: 0.1422 - val_loss: 2.7773 - val_accuracy: 0.1475\n",
            "Epoch 20/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.7786 - accuracy: 0.1438 - val_loss: 2.7808 - val_accuracy: 0.1475\n",
            "Epoch 21/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.7788 - accuracy: 0.1429 - val_loss: 2.7850 - val_accuracy: 0.1475\n",
            "Epoch 22/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 2.7791 - accuracy: 0.1425 - val_loss: 2.7756 - val_accuracy: 0.1475\n",
            "Epoch 23/30\n",
            "119305/119305 [==============================] - 10s 83us/step - loss: 2.7788 - accuracy: 0.1445 - val_loss: 2.7818 - val_accuracy: 0.1475\n",
            "Epoch 24/30\n",
            "119305/119305 [==============================] - 10s 85us/step - loss: 2.7793 - accuracy: 0.1430 - val_loss: 2.7869 - val_accuracy: 0.1475\n",
            "Epoch 25/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.7787 - accuracy: 0.1430 - val_loss: 2.7782 - val_accuracy: 0.1392\n",
            "Epoch 26/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.7792 - accuracy: 0.1424 - val_loss: 2.7775 - val_accuracy: 0.1475\n",
            "Epoch 27/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.7789 - accuracy: 0.1436 - val_loss: 2.7835 - val_accuracy: 0.1392\n",
            "Epoch 28/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.7791 - accuracy: 0.1434 - val_loss: 2.7746 - val_accuracy: 0.1475\n",
            "Epoch 29/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.7789 - accuracy: 0.1433 - val_loss: 2.7745 - val_accuracy: 0.1475\n",
            "Epoch 30/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.7790 - accuracy: 0.1426 - val_loss: 2.7740 - val_accuracy: 0.1475\n",
            "[[   0    0    0    0    0    0    0    0  994    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0  617    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1127    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0  960    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1340    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 2406    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0  731    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0  346    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4398    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4152    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0  182    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0  776    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 3390    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0  616    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1920    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0  229    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1396    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0  226    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0  987    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0  746    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0  691    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1597    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]]\n",
            "0.14745029671103363\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       994\n",
            "           1       0.00      0.00      0.00       617\n",
            "           2       0.00      0.00      0.00      1127\n",
            "           3       0.00      0.00      0.00       960\n",
            "           4       0.00      0.00      0.00      1340\n",
            "           5       0.00      0.00      0.00      2406\n",
            "           6       0.00      0.00      0.00       731\n",
            "           7       0.00      0.00      0.00       346\n",
            "           8       0.15      1.00      0.26      4398\n",
            "           9       0.00      0.00      0.00      4152\n",
            "          10       0.00      0.00      0.00       182\n",
            "          11       0.00      0.00      0.00       776\n",
            "          12       0.00      0.00      0.00      3390\n",
            "          13       0.00      0.00      0.00       616\n",
            "          14       0.00      0.00      0.00      1920\n",
            "          15       0.00      0.00      0.00       229\n",
            "          16       0.00      0.00      0.00      1396\n",
            "          17       0.00      0.00      0.00       226\n",
            "          18       0.00      0.00      0.00       987\n",
            "          19       0.00      0.00      0.00       746\n",
            "          20       0.00      0.00      0.00       691\n",
            "          21       0.00      0.00      0.00      1597\n",
            "\n",
            "    accuracy                           0.15     29827\n",
            "   macro avg       0.01      0.05      0.01     29827\n",
            "weighted avg       0.02      0.15      0.04     29827\n",
            "\n",
            "1.0\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_11 (Conv2D)           (None, 200, 3, 16)        160       \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 200, 3, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 100, 1, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 1024)              1639424   \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 22)                22550     \n",
            "=================================================================\n",
            "Total params: 1,662,134\n",
            "Trainable params: 1,662,134\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 119305 samples, validate on 29827 samples\n",
            "Epoch 1/30\n",
            "119305/119305 [==============================] - 10s 85us/step - loss: 933.1135 - accuracy: 0.1425 - val_loss: 5.8697 - val_accuracy: 0.1473\n",
            "Epoch 2/30\n",
            "119305/119305 [==============================] - 10s 83us/step - loss: 41.9261 - accuracy: 0.1364 - val_loss: 3.3319 - val_accuracy: 0.1392\n",
            "Epoch 3/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 4.7095 - accuracy: 0.1360 - val_loss: 2.9581 - val_accuracy: 0.1138\n",
            "Epoch 4/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 71.8655 - accuracy: 0.1368 - val_loss: 3.9189 - val_accuracy: 0.1482\n",
            "Epoch 5/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 22.0594 - accuracy: 0.1448 - val_loss: 2.8846 - val_accuracy: 0.1229\n",
            "Epoch 6/30\n",
            "119305/119305 [==============================] - 10s 83us/step - loss: 3.0050 - accuracy: 0.1445 - val_loss: 2.8261 - val_accuracy: 0.1229\n",
            "Epoch 7/30\n",
            "119305/119305 [==============================] - 10s 83us/step - loss: 2.9381 - accuracy: 0.1424 - val_loss: 2.8623 - val_accuracy: 0.1484\n",
            "Epoch 8/30\n",
            "119305/119305 [==============================] - 10s 83us/step - loss: 379.2723 - accuracy: 0.1369 - val_loss: 2.8797 - val_accuracy: 0.1392\n",
            "Epoch 9/30\n",
            "119305/119305 [==============================] - 10s 83us/step - loss: 2.8713 - accuracy: 0.1348 - val_loss: 2.9070 - val_accuracy: 0.1392\n",
            "Epoch 10/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.8746 - accuracy: 0.1333 - val_loss: 2.9553 - val_accuracy: 0.1137\n",
            "Epoch 11/30\n",
            "119305/119305 [==============================] - 10s 83us/step - loss: 2.8735 - accuracy: 0.1345 - val_loss: 2.8744 - val_accuracy: 0.1475\n",
            "Epoch 12/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.8720 - accuracy: 0.1339 - val_loss: 2.8783 - val_accuracy: 0.1475\n",
            "Epoch 13/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.8754 - accuracy: 0.1334 - val_loss: 2.9491 - val_accuracy: 0.1392\n",
            "Epoch 14/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.8757 - accuracy: 0.1349 - val_loss: 2.9598 - val_accuracy: 0.1137\n",
            "Epoch 15/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 2.8722 - accuracy: 0.1341 - val_loss: 2.8990 - val_accuracy: 0.1137\n",
            "Epoch 16/30\n",
            "119305/119305 [==============================] - 10s 81us/step - loss: 2.8751 - accuracy: 0.1365 - val_loss: 2.9198 - val_accuracy: 0.1392\n",
            "Epoch 17/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.8753 - accuracy: 0.1330 - val_loss: 2.8890 - val_accuracy: 0.1392\n",
            "Epoch 18/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.8745 - accuracy: 0.1338 - val_loss: 2.8722 - val_accuracy: 0.1392\n",
            "Epoch 19/30\n",
            "119305/119305 [==============================] - 10s 82us/step - loss: 2.8741 - accuracy: 0.1345 - val_loss: 2.8389 - val_accuracy: 0.1392\n",
            "Epoch 20/30\n",
            "119305/119305 [==============================] - 10s 85us/step - loss: 2.8733 - accuracy: 0.1349 - val_loss: 2.8674 - val_accuracy: 0.1475\n",
            "Epoch 21/30\n",
            "119305/119305 [==============================] - 10s 84us/step - loss: 2.8737 - accuracy: 0.1325 - val_loss: 2.9143 - val_accuracy: 0.1475\n",
            "Epoch 22/30\n",
            "119305/119305 [==============================] - 10s 84us/step - loss: 2.8727 - accuracy: 0.1336 - val_loss: 2.8567 - val_accuracy: 0.1475\n",
            "Epoch 23/30\n",
            "119305/119305 [==============================] - 10s 84us/step - loss: 2.8739 - accuracy: 0.1358 - val_loss: 2.8583 - val_accuracy: 0.1475\n",
            "Epoch 24/30\n",
            "119305/119305 [==============================] - 10s 84us/step - loss: 2.8750 - accuracy: 0.1336 - val_loss: 3.0337 - val_accuracy: 0.0807\n",
            "Epoch 25/30\n",
            "119305/119305 [==============================] - 10s 87us/step - loss: 2.8755 - accuracy: 0.1372 - val_loss: 2.8452 - val_accuracy: 0.1392\n",
            "Epoch 26/30\n",
            "119305/119305 [==============================] - 10s 85us/step - loss: 2.8718 - accuracy: 0.1340 - val_loss: 2.8673 - val_accuracy: 0.1475\n",
            "Epoch 27/30\n",
            "119305/119305 [==============================] - 10s 84us/step - loss: 2.8753 - accuracy: 0.1347 - val_loss: 2.9276 - val_accuracy: 0.0807\n",
            "Epoch 28/30\n",
            "119305/119305 [==============================] - 10s 84us/step - loss: 2.8771 - accuracy: 0.1327 - val_loss: 2.8977 - val_accuracy: 0.1137\n",
            "Epoch 29/30\n",
            "119305/119305 [==============================] - 10s 83us/step - loss: 2.8707 - accuracy: 0.1343 - val_loss: 2.8901 - val_accuracy: 0.1475\n",
            "Epoch 30/30\n",
            "119305/119305 [==============================] - 10s 84us/step - loss: 2.8726 - accuracy: 0.1334 - val_loss: 2.8983 - val_accuracy: 0.1392\n",
            "[[   0    0    0    0    0    0    0    0    0  994    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  617    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1127    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  960    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1340    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2406    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  731    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  346    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4398    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4152    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  182    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  776    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3390    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  616    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1920    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  229    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1396    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  226    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  987    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  746    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  691    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1597    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]]\n",
            "0.13920273577631007\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       994\n",
            "           1       0.00      0.00      0.00       617\n",
            "           2       0.00      0.00      0.00      1127\n",
            "           3       0.00      0.00      0.00       960\n",
            "           4       0.00      0.00      0.00      1340\n",
            "           5       0.00      0.00      0.00      2406\n",
            "           6       0.00      0.00      0.00       731\n",
            "           7       0.00      0.00      0.00       346\n",
            "           8       0.00      0.00      0.00      4398\n",
            "           9       0.14      1.00      0.24      4152\n",
            "          10       0.00      0.00      0.00       182\n",
            "          11       0.00      0.00      0.00       776\n",
            "          12       0.00      0.00      0.00      3390\n",
            "          13       0.00      0.00      0.00       616\n",
            "          14       0.00      0.00      0.00      1920\n",
            "          15       0.00      0.00      0.00       229\n",
            "          16       0.00      0.00      0.00      1396\n",
            "          17       0.00      0.00      0.00       226\n",
            "          18       0.00      0.00      0.00       987\n",
            "          19       0.00      0.00      0.00       746\n",
            "          20       0.00      0.00      0.00       691\n",
            "          21       0.00      0.00      0.00      1597\n",
            "\n",
            "    accuracy                           0.14     29827\n",
            "   macro avg       0.01      0.05      0.01     29827\n",
            "weighted avg       0.02      0.14      0.03     29827\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}